{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lab4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "3suJfqw4OdIB"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf, requests as rqst, io\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "rnd = np.random.randint"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CpfL4lOIIU0x",
        "outputId": "c36cffb4-e635-4b92-9aae-88ca91e3274e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1bwxXcKUAgf"
      },
      "source": [
        "#create the grouped dataset based on the data from each participant\n",
        "vlad_file = open(\"/content/drive/MyDrive/NLP/datavlad.txt\")\n",
        "vlad_sentences = vlad_file.read().split('.')[:-1]\n",
        "\n",
        "artem_file = open(\"/content/drive/MyDrive/NLP/dataartem.txt\")\n",
        "artem_sentences = artem_file.read().split('.')[:-1]\n",
        "\n",
        "ks_file = open(\"/content/drive/MyDrive/NLP/dataks.txt\")\n",
        "ks_sentences = ks_file.read().split('.')[:-1]"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "xXFtRDHpobtl",
        "outputId": "fdf45b62-7e91-4936-cad6-f33489d76d0f"
      },
      "source": [
        "new_df = []\n",
        "\n",
        "for new in vlad_sentences:\n",
        "  new_df.append({'Sentence':new, 'Label':'neural network art'})\n",
        "\n",
        "for new in ks_sentences:\n",
        "  new_df.append({'Sentence':new, 'Label':'climate change'})\n",
        "\n",
        "for new in artem_sentences:\n",
        "  new_df.append({'Sentence':new, 'Label':'neural network recognition'})\n",
        "\n",
        "new_df = pd.DataFrame(data=new_df, columns=['Sentence', 'Label'])\n",
        "\n",
        "new_df['Target'] = new_df['Label']\n",
        "new_df.replace({'Target':{'neural network art':1, 'climate change':0, 'neural network recognition':0}}, inplace=True)\n",
        "new_df"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Label</th>\n",
              "      <th>Target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>In the past few years, many artists have begun...</td>\n",
              "      <td>neural network art</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\\nIn computer vision and perceptual psychology...</td>\n",
              "      <td>neural network art</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\\nIn other words, modern neural models lend th...</td>\n",
              "      <td>neural network art</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\\nThe most prominent tool in neural art at the...</td>\n",
              "      <td>neural network art</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\\nGiven a large collection of images of a spec...</td>\n",
              "      <td>neural network art</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>302</th>\n",
              "      <td>\\nIn May 2017, a man was arrested using an aut...</td>\n",
              "      <td>neural network recognition</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>303</th>\n",
              "      <td>[68] Live facial recognition has been trialled...</td>\n",
              "      <td>neural network recognition</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>304</th>\n",
              "      <td>[69] In August 2020 the Court of Appeal ruled ...</td>\n",
              "      <td>neural network recognition</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>305</th>\n",
              "      <td>S</td>\n",
              "      <td>neural network recognition</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>306</th>\n",
              "      <td>Department of State operates one of the large...</td>\n",
              "      <td>neural network recognition</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>307 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              Sentence  ... Target\n",
              "0    In the past few years, many artists have begun...  ...      1\n",
              "1    \\nIn computer vision and perceptual psychology...  ...      1\n",
              "2    \\nIn other words, modern neural models lend th...  ...      1\n",
              "3    \\nThe most prominent tool in neural art at the...  ...      1\n",
              "4    \\nGiven a large collection of images of a spec...  ...      1\n",
              "..                                                 ...  ...    ...\n",
              "302  \\nIn May 2017, a man was arrested using an aut...  ...      0\n",
              "303  [68] Live facial recognition has been trialled...  ...      0\n",
              "304  [69] In August 2020 the Court of Appeal ruled ...  ...      0\n",
              "305                                                  S  ...      0\n",
              "306   Department of State operates one of the large...  ...      0\n",
              "\n",
              "[307 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RmSlaX2DJzM"
      },
      "source": [
        "# vectorization of text\n",
        "max_tokens = 10000\n",
        "\n",
        "sentences = vlad_sentences+artem_sentences+ks_sentences\n",
        "tokens_count = 0\n",
        "for new in sentences:\n",
        "  tokens_count+=len(new.split())\n",
        "avg_tokens = round(tokens_count/len(sentences))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fm1gjy-eUHB4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db8884f7-baf1-43f1-d1d9-9dc2d5eaf817"
      },
      "source": [
        "#tokenization and embedding\n",
        "text_vectorizer = TextVectorization(max_tokens=max_tokens, \n",
        "                                    standardize=\"lower_and_strip_punctuation\", \n",
        "                                    split=\"whitespace\", \n",
        "                                    ngrams=None, \n",
        "                                    output_mode=\"int\",\n",
        "                                    output_sequence_length=avg_tokens, \n",
        "                                    pad_to_max_tokens=True)\n",
        "\n",
        "text_vectorizer.adapt(new_df['Sentence'])\n",
        "\n",
        "text_vectorizer(new_df['Sentence'])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(307, 25), dtype=int64, numpy=\n",
              "array([[   6,    2,  212, ...,  826,    6, 1800],\n",
              "       [   6,  303,  328, ...,    0,    0,    0],\n",
              "       [   6,   62,  325, ...,  139,  455,  266],\n",
              "       ...,\n",
              "       [2051,    6, 1943, ...,  251,  101,    6],\n",
              "       [ 575,    0,    0, ...,    0,    0,    0],\n",
              "       [ 763,    3,  363, ...,   24,  102,  524]])>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HsUT7y2avSdJ",
        "outputId": "4c3ad017-c748-4f87-b855-be926d43a762"
      },
      "source": [
        "embedding = layers.Embedding(input_dim=max_tokens, # set input shape\n",
        "                             output_dim=128, # set size of embedding vector\n",
        "                             embeddings_initializer=\"uniform\", # default, intialize randomly\n",
        "                             input_length=avg_tokens) # how long is each input\n",
        "\n",
        "embedding(text_vectorizer(new_df['Sentence']))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(307, 25, 128), dtype=float32, numpy=\n",
              "array([[[-0.02110715,  0.02350539,  0.04923756, ..., -0.0399381 ,\n",
              "          0.01319214, -0.01607747],\n",
              "        [ 0.01041071, -0.0288753 , -0.01059166, ...,  0.03674814,\n",
              "          0.04063675,  0.00346867],\n",
              "        [-0.02473914,  0.00615771,  0.00389104, ...,  0.03205865,\n",
              "          0.02993964,  0.03718005],\n",
              "        ...,\n",
              "        [-0.00638632,  0.00332669,  0.0345796 , ...,  0.01410979,\n",
              "          0.01467253,  0.01910256],\n",
              "        [-0.02110715,  0.02350539,  0.04923756, ..., -0.0399381 ,\n",
              "          0.01319214, -0.01607747],\n",
              "        [ 0.02502717,  0.04445639, -0.04494101, ...,  0.04625538,\n",
              "         -0.01475898,  0.00666505]],\n",
              "\n",
              "       [[-0.02110715,  0.02350539,  0.04923756, ..., -0.0399381 ,\n",
              "          0.01319214, -0.01607747],\n",
              "        [-0.04333587, -0.04216122, -0.04893682, ..., -0.03010637,\n",
              "          0.02679728,  0.00208858],\n",
              "        [ 0.04383955,  0.04991759,  0.04202527, ..., -0.00055216,\n",
              "         -0.04173743, -0.02878193],\n",
              "        ...,\n",
              "        [ 0.00797696, -0.03752228,  0.04662882, ...,  0.03473437,\n",
              "         -0.04883652, -0.02484034],\n",
              "        [ 0.00797696, -0.03752228,  0.04662882, ...,  0.03473437,\n",
              "         -0.04883652, -0.02484034],\n",
              "        [ 0.00797696, -0.03752228,  0.04662882, ...,  0.03473437,\n",
              "         -0.04883652, -0.02484034]],\n",
              "\n",
              "       [[-0.02110715,  0.02350539,  0.04923756, ..., -0.0399381 ,\n",
              "          0.01319214, -0.01607747],\n",
              "        [ 0.03974103,  0.01927913,  0.00243645, ..., -0.01783171,\n",
              "         -0.02247568, -0.04721075],\n",
              "        [ 0.03048917, -0.02185805, -0.03832174, ..., -0.00952557,\n",
              "          0.03167902,  0.01887831],\n",
              "        ...,\n",
              "        [ 0.00167968,  0.02690304, -0.00247955, ..., -0.02794953,\n",
              "          0.04666099, -0.0416844 ],\n",
              "        [-0.03489859,  0.01355788,  0.03870389, ...,  0.0135393 ,\n",
              "          0.00991635, -0.03136424],\n",
              "        [-0.01265965,  0.01658479,  0.01674056, ..., -0.0422701 ,\n",
              "         -0.04456262, -0.0180092 ]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[ 0.00866498, -0.02568271, -0.03307893, ..., -0.02550237,\n",
              "          0.03508874, -0.04294019],\n",
              "        [-0.02110715,  0.02350539,  0.04923756, ..., -0.0399381 ,\n",
              "          0.01319214, -0.01607747],\n",
              "        [-0.03930467, -0.00773666,  0.04611844, ...,  0.04017274,\n",
              "         -0.01792615, -0.0083345 ],\n",
              "        ...,\n",
              "        [-0.04458233, -0.00643039,  0.01635833, ...,  0.00941458,\n",
              "         -0.04548265, -0.01117357],\n",
              "        [-0.03658918,  0.03441146,  0.00600834, ..., -0.02937831,\n",
              "         -0.0267386 ,  0.02792117],\n",
              "        [-0.02110715,  0.02350539,  0.04923756, ..., -0.0399381 ,\n",
              "          0.01319214, -0.01607747]],\n",
              "\n",
              "       [[-0.04457573,  0.02645668,  0.01693232, ...,  0.04652235,\n",
              "         -0.04004706, -0.01273767],\n",
              "        [ 0.00797696, -0.03752228,  0.04662882, ...,  0.03473437,\n",
              "         -0.04883652, -0.02484034],\n",
              "        [ 0.00797696, -0.03752228,  0.04662882, ...,  0.03473437,\n",
              "         -0.04883652, -0.02484034],\n",
              "        ...,\n",
              "        [ 0.00797696, -0.03752228,  0.04662882, ...,  0.03473437,\n",
              "         -0.04883652, -0.02484034],\n",
              "        [ 0.00797696, -0.03752228,  0.04662882, ...,  0.03473437,\n",
              "         -0.04883652, -0.02484034],\n",
              "        [ 0.00797696, -0.03752228,  0.04662882, ...,  0.03473437,\n",
              "         -0.04883652, -0.02484034]],\n",
              "\n",
              "       [[ 0.04487414, -0.04962337, -0.0403296 , ...,  0.00544744,\n",
              "          0.03462983,  0.04963977],\n",
              "        [-0.02441254,  0.04715895, -0.00822167, ...,  0.02408897,\n",
              "         -0.02974893, -0.00689477],\n",
              "        [ 0.0488455 ,  0.03291515, -0.04045756, ..., -0.02412249,\n",
              "         -0.0020515 ,  0.04254851],\n",
              "        ...,\n",
              "        [-0.024753  , -0.01516239,  0.01659069, ..., -0.00835363,\n",
              "         -0.01422413, -0.00468242],\n",
              "        [ 0.03801635, -0.03969651, -0.02628475, ...,  0.01299432,\n",
              "          0.0241413 , -0.02618775],\n",
              "        [-0.02819335, -0.04472606, -0.00252544, ...,  0.04114958,\n",
              "          0.00632381,  0.04887047]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "7CjG_Vz2OWhX",
        "outputId": "f9db6107-4e74-4a91-a240-6b6d92f08e1c"
      },
      "source": [
        "# import libraries\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_split, test_split = train_test_split(new_df, train_size=0.8, test_size=0.2)\n",
        "train_split"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Label</th>\n",
              "      <th>Target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>197</th>\n",
              "      <td>Democrats also reported much higher confidenc...</td>\n",
              "      <td>climate change</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81</th>\n",
              "      <td>\\nWhile the first stage deep CNN classifier is...</td>\n",
              "      <td>neural network art</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>303</th>\n",
              "      <td>[68] Live facial recognition has been trialled...</td>\n",
              "      <td>neural network recognition</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>\\nTransfer learning allows the adaptation or r...</td>\n",
              "      <td>neural network art</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92</th>\n",
              "      <td>\\nThis type of approach relies on the assumpti...</td>\n",
              "      <td>neural network art</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>\\nIn this paper, we explore the secret nature ...</td>\n",
              "      <td>neural network art</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>162</th>\n",
              "      <td>This process is known as the greenhouse effec...</td>\n",
              "      <td>climate change</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77</th>\n",
              "      <td>\\nThe findings revealed a strong correlation b...</td>\n",
              "      <td>neural network art</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102</th>\n",
              "      <td>\\nWe can see that our method successfully lear...</td>\n",
              "      <td>neural network art</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>\\nThus, the visually most appealing images are...</td>\n",
              "      <td>neural network art</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>245 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              Sentence  ... Target\n",
              "197   Democrats also reported much higher confidenc...  ...      0\n",
              "81   \\nWhile the first stage deep CNN classifier is...  ...      1\n",
              "303  [68] Live facial recognition has been trialled...  ...      0\n",
              "70   \\nTransfer learning allows the adaptation or r...  ...      1\n",
              "92   \\nThis type of approach relies on the assumpti...  ...      1\n",
              "..                                                 ...  ...    ...\n",
              "95   \\nIn this paper, we explore the secret nature ...  ...      1\n",
              "162   This process is known as the greenhouse effec...  ...      0\n",
              "77   \\nThe findings revealed a strong correlation b...  ...      1\n",
              "102  \\nWe can see that our method successfully lear...  ...      1\n",
              "48   \\nThus, the visually most appealing images are...  ...      1\n",
              "\n",
              "[245 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIu3Fp7fttP0"
      },
      "source": [
        "#import libraries for classification\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "def calculate_results(y_true, y_pred):\n",
        "  \"\"\"\n",
        "  Calculates model accuracy, precision, recall and f1 score of a binary classification model.\n",
        "\n",
        "  Args:\n",
        "  -----\n",
        "  y_true = true labels in the form of a 1D array\n",
        "  y_pred = predicted labels in the form of a 1D array\n",
        "\n",
        "  Returns a dictionary of accuracy, precision, recall, f1-score.\n",
        "  \"\"\"\n",
        "  # Calculate model accuracy\n",
        "  model_accuracy = accuracy_score(y_true, y_pred) * 100\n",
        "  # Calculate model precision, recall and f1 score using \"weighted\" average\n",
        "  model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
        "  model_results = {\"accuracy\": model_accuracy,\n",
        "                  \"precision\": model_precision,\n",
        "                  \"recall\": model_recall,\n",
        "                  \"f1\": model_f1}\n",
        "  return model_results\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RpW7qBXJJFGR"
      },
      "source": [
        "#lstm\n",
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "x = layers.LSTM(64)(x) # return vector for whole sequence\n",
        "x = layers.Dense(64, activation=\"relu\")(x) # optional dense layer on top of output of LSTM cell\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_lstm = tf.keras.Model(inputs, outputs, name=\"model_LSTM\")\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQaasE2SLnUL"
      },
      "source": [
        "model_lstm.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g6TLqhlbLtbz",
        "outputId": "d275af41-1a71-498c-d023-9d36e317b521"
      },
      "source": [
        "model_lstm.summary()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_LSTM\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization (TextVec  (None, 25)               0         \n",
            " torization)                                                     \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 25, 128)           1280000   \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 64)                49408     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,333,633\n",
            "Trainable params: 1,333,633\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AkmqLX8BLvO8",
        "outputId": "6ebe8973-2b7f-401e-af13-96694111d251"
      },
      "source": [
        "model_lstm_history = model_lstm.fit(train_split['Sentence'],\n",
        "                              train_split['Target'],\n",
        "                              epochs=9,\n",
        "                              validation_data=(test_split['Sentence'], test_split['Target']))\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/9\n",
            "8/8 [==============================] - 6s 109ms/step - loss: 0.6820 - accuracy: 0.6408 - val_loss: 0.6529 - val_accuracy: 0.6774\n",
            "Epoch 2/9\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.6396 - accuracy: 0.6531 - val_loss: 0.5969 - val_accuracy: 0.6774\n",
            "Epoch 3/9\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.5370 - accuracy: 0.6531 - val_loss: 0.4952 - val_accuracy: 0.6935\n",
            "Epoch 4/9\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.3058 - accuracy: 0.8980 - val_loss: 0.2839 - val_accuracy: 0.9355\n",
            "Epoch 5/9\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.1108 - accuracy: 0.9918 - val_loss: 0.3611 - val_accuracy: 0.8548\n",
            "Epoch 6/9\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0297 - accuracy: 0.9959 - val_loss: 0.4767 - val_accuracy: 0.8710\n",
            "Epoch 7/9\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.4898 - val_accuracy: 0.9032\n",
            "Epoch 8/9\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.5407 - val_accuracy: 0.9032\n",
            "Epoch 9/9\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 8.5549e-04 - accuracy: 1.0000 - val_loss: 0.5751 - val_accuracy: 0.9032\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O2qS5-pSMLqc",
        "outputId": "4df67821-6a8d-459b-d17d-4402bc2bb568"
      },
      "source": [
        "model_lstm_pred_probs = model_lstm.predict(test_split['Sentence'])\n",
        "model_lstm_preds = tf.squeeze(tf.round(model_lstm_pred_probs))\n",
        "calculate_results(y_true=test_split['Target'], y_pred=model_lstm_preds)\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 90.32258064516128,\n",
              " 'f1': 0.9043497808249972,\n",
              " 'precision': 0.9074780058651026,\n",
              " 'recall': 0.9032258064516129}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4lYimUjNkUZ"
      },
      "source": [
        "#GRU\n",
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "x = layers.GRU(64)(x) \n",
        "x = layers.Dense(64, activation=\"relu\")(x) # optional dense layer after GRU cell\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_gru = tf.keras.Model(inputs, outputs, name=\"model_GRU\")\n"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QQzEkvGNkWI"
      },
      "source": [
        "model_gru.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P63GbmYDNkYR",
        "outputId": "375259d6-b103-46d9-bec3-5381a0e05a7a"
      },
      "source": [
        "model_gru_history = model_gru.fit(train_split['Sentence'],\n",
        "                              train_split['Target'],\n",
        "                              epochs=9,\n",
        "                              validation_data=(test_split['Sentence'], test_split['Target']))\n"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/9\n",
            "8/8 [==============================] - 3s 90ms/step - loss: 0.6664 - accuracy: 0.6776 - val_loss: 0.6454 - val_accuracy: 0.7742\n",
            "Epoch 2/9\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.5699 - accuracy: 0.8939 - val_loss: 0.5451 - val_accuracy: 0.7742\n",
            "Epoch 3/9\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.3590 - accuracy: 0.9388 - val_loss: 0.3493 - val_accuracy: 0.8548\n",
            "Epoch 4/9\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0736 - accuracy: 0.9918 - val_loss: 0.2134 - val_accuracy: 0.9032\n",
            "Epoch 5/9\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0085 - accuracy: 0.9959 - val_loss: 0.4803 - val_accuracy: 0.9194\n",
            "Epoch 6/9\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 2.0660e-04 - accuracy: 1.0000 - val_loss: 0.5081 - val_accuracy: 0.9355\n",
            "Epoch 7/9\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 9.9250e-05 - accuracy: 1.0000 - val_loss: 0.5444 - val_accuracy: 0.9355\n",
            "Epoch 8/9\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 7.0301e-05 - accuracy: 1.0000 - val_loss: 0.5607 - val_accuracy: 0.9355\n",
            "Epoch 9/9\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 5.9016e-05 - accuracy: 1.0000 - val_loss: 0.5686 - val_accuracy: 0.9355\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ehia-s8tNkaV",
        "outputId": "e32234c2-24f5-41d6-83e3-c713a0f86319"
      },
      "source": [
        "model_gru_pred_probs = model_gru.predict(test_split['Sentence'])\n",
        "model_gru_preds = tf.squeeze(tf.round(model_gru_pred_probs))\n",
        "calculate_results(y_true=test_split['Target'], y_pred=model_gru_preds)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 93.54838709677419,\n",
              " 'f1': 0.9345362656453587,\n",
              " 'precision': 0.9358911697621375,\n",
              " 'recall': 0.9354838709677419}"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8L6so5LeSHn5"
      },
      "source": [
        "#bidirectional LSTM\n",
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "# x = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(x) # stacking RNN layers requires return_sequences=True\n",
        "x = layers.Bidirectional(layers.LSTM(64))(x) # bidirectional goes both ways so has double the parameters of a regular LSTM layer\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_bi_lstm = tf.keras.Model(inputs, outputs, name=\"model_Bi_lstm\")\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZDUsyfeSOuo"
      },
      "source": [
        "model_bi_lstm.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5USTZa7zSQc3",
        "outputId": "10f7a916-532b-468a-c129-a33284b91ed6"
      },
      "source": [
        "model_bi_lstm.summary()\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_Bi_lstm\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization (TextVec  (None, 25)               0         \n",
            " torization)                                                     \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 25, 128)           1280000   \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 128)              98816     \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,378,945\n",
            "Trainable params: 1,378,945\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfpOLQssSQ6k",
        "outputId": "276746f2-8c0c-4c86-b7c2-687d53a57a92"
      },
      "source": [
        "model_bi_lstm_history = model_bi_lstm.fit(train_split['Sentence'],\n",
        "                              train_split['Target'],\n",
        "                              epochs=9,\n",
        "                              validation_data=(test_split['Sentence'], test_split['Target']))\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/9\n",
            "8/8 [==============================] - 5s 159ms/step - loss: 0.6447 - accuracy: 0.6939 - val_loss: 0.5853 - val_accuracy: 0.7581\n",
            "Epoch 2/9\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 0.4139 - accuracy: 0.9143 - val_loss: 0.3579 - val_accuracy: 0.8226\n",
            "Epoch 3/9\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.1215 - accuracy: 0.9755 - val_loss: 0.2186 - val_accuracy: 0.8871\n",
            "Epoch 4/9\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.0157 - accuracy: 1.0000 - val_loss: 0.1906 - val_accuracy: 0.9516\n",
            "Epoch 5/9\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.2573 - val_accuracy: 0.9355\n",
            "Epoch 6/9\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.2915 - val_accuracy: 0.9355\n",
            "Epoch 7/9\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3761 - val_accuracy: 0.9032\n",
            "Epoch 8/9\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.3308 - val_accuracy: 0.9194\n",
            "Epoch 9/9\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 6.3848e-04 - accuracy: 1.0000 - val_loss: 0.3204 - val_accuracy: 0.9194\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pAoIphfFFtzV",
        "outputId": "b134843b-7ad5-4c70-f19a-45fffac9bc64"
      },
      "source": [
        "model_bi_lstm_pred_probs = model_bi_lstm.predict(test_split['Sentence'])\n",
        "model_bi_lstm_preds = tf.squeeze(tf.round(model_bi_lstm_pred_probs))\n",
        "calculate_results(y_true=test_split['Target'], y_pred=model_bi_lstm_preds)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 91.93548387096774,\n",
              " 'f1': 0.919852502061748,\n",
              " 'precision': 0.9208722041137462,\n",
              " 'recall': 0.9193548387096774}"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IuxMkSKeTIBF"
      },
      "source": [
        "#bidirectional GRU\n",
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "x = layers.Bidirectional(layers.GRU(64))(x) # bidirectional goes both ways so has double the parameters of a regular LSTM layer\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_bi_gru = tf.keras.Model(inputs, outputs, name=\"model_Bi_gru\")"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wTDfkosTOQx"
      },
      "source": [
        "model_bi_gru.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xX0PT4rkTQZ4",
        "outputId": "a1409e03-0ae3-4cef-b29d-9bc444e19a69"
      },
      "source": [
        "model_bi_gru.summary()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_Bi_gru\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization (TextVec  (None, 25)               0         \n",
            " torization)                                                     \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 25, 128)           1280000   \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirectio  (None, 128)              74496     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,354,625\n",
            "Trainable params: 1,354,625\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AUA9dZgATS-R",
        "outputId": "b7ccd12c-5916-427b-e7e8-04bc4b51c9e4"
      },
      "source": [
        "model_bi_gru_history = model_bi_gru.fit(train_split['Sentence'],\n",
        "                              train_split['Target'],\n",
        "                              epochs=9,\n",
        "                              validation_data=(test_split['Sentence'], test_split['Target']))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/9\n",
            "8/8 [==============================] - 5s 149ms/step - loss: 0.6417 - accuracy: 0.7102 - val_loss: 0.5849 - val_accuracy: 0.7419\n",
            "Epoch 2/9\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.4806 - accuracy: 0.8327 - val_loss: 0.4683 - val_accuracy: 0.7903\n",
            "Epoch 3/9\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.2816 - accuracy: 0.9020 - val_loss: 0.2887 - val_accuracy: 0.8710\n",
            "Epoch 4/9\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.0602 - accuracy: 0.9959 - val_loss: 0.1128 - val_accuracy: 0.9516\n",
            "Epoch 5/9\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.1842 - val_accuracy: 0.9677\n",
            "Epoch 6/9\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 2.9609e-04 - accuracy: 1.0000 - val_loss: 0.2932 - val_accuracy: 0.9516\n",
            "Epoch 7/9\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 3.1300e-04 - accuracy: 1.0000 - val_loss: 0.3069 - val_accuracy: 0.9516\n",
            "Epoch 8/9\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 2.5144e-04 - accuracy: 1.0000 - val_loss: 0.3172 - val_accuracy: 0.9516\n",
            "Epoch 9/9\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 1.6383e-04 - accuracy: 1.0000 - val_loss: 0.3257 - val_accuracy: 0.9516\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2UyLqg9Gl3n",
        "outputId": "c21fb91a-bc12-43a7-89f4-96f1768e232e"
      },
      "source": [
        "model_bi_gru_pred_probs = model_bi_gru.predict(test_split['Sentence'])\n",
        "model_bi_gru_preds = tf.squeeze(tf.round(model_bi_gru_pred_probs))\n",
        "calculate_results(y_true=test_split['Target'], y_pred=model_bi_gru_preds)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 95.16129032258065,\n",
              " 'f1': 0.9512771858122903,\n",
              " 'precision': 0.9515141943380583,\n",
              " 'recall': 0.9516129032258065}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YjdJ4sLkHHLu"
      },
      "source": [
        "Every model has 9 epochs for learning. The best results were shown by bidirectional GRU model."
      ]
    }
  ]
}