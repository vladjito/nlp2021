{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "3suJfqw4OdIB"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf, requests as rqst, io\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "rnd = np.random.randint"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YgkSs_aru9fQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a8409d4-8528-4d40-f347-2a404c1af727"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1bwxXcKUAgf",
        "outputId": "040f34cd-c69d-4206-ac2f-f8add4d5e9b6"
      },
      "source": [
        "#create the grouped dataset based on the data from each participant\n",
        "vlad_file = open(\"/content/drive/MyDrive/NLP/datavlad.txt\")\n",
        "vlad_sentences = vlad_file.read().split('.')[:-1]\n",
        "\n",
        "artem_file = open(\"/content/drive/MyDrive/NLP/dataartem.txt\")\n",
        "artem_sentences = artem_file.read().split('.')[:-1]\n",
        "\n",
        "ks_file = open(\"/content/drive/MyDrive/NLP/dataks.txt\")\n",
        "ks_sentences = ks_file.read().split('.')[:-1]\n",
        "\n",
        "vlad_sentences\n",
        "\n",
        "artem_sentences\n",
        "\n",
        "ks_sentences"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Scientists attribute the global warming trend observed since the mid-20th century to the human expansion of the \"greenhouse effect\"1 — warming that results when the atmosphere traps heat radiating from Earth toward space',\n",
              " '\\nCertain gases in the atmosphere block heat from escaping',\n",
              " ' Long-lived gases that remain semi-permanently in the atmosphere and do not respond physically or chemically to changes in temperature are described as \"forcing\" climate change',\n",
              " ' Gases, such as water vapor, which respond physically or chemically to changes in temperature are seen as \"feedbacks',\n",
              " '\"\\nGlobal climate change has already had observable effects on the environment',\n",
              " ' Glaciers have shrunk, ice on rivers and lakes is breaking up earlier, plant and animal ranges have shifted and trees are flowering sooner',\n",
              " '\\nEffects that scientists had predicted in the past would result from global climate change are now occurring: loss of sea ice, accelerated sea level rise and longer, more intense heat waves',\n",
              " '\\nScientists have high confidence that global temperatures will continue to rise for decades to come, largely due to greenhouse gases produced by human activities',\n",
              " ' The Intergovernmental Panel on Climate Change (IPCC), which includes more than 1,300 scientists from the United States and other countries, forecasts a temperature rise of 2',\n",
              " '5 to 10 degrees Fahrenheit over the next century',\n",
              " '\\nAccording to the IPCC, the extent of climate change effects on individual regions will vary over time and with the ability of different societal and environmental systems to mitigate or adapt to change',\n",
              " '\\nThe IPCC predicts that increases in global mean temperature of less than 1',\n",
              " '8 to 5',\n",
              " '4 degrees Fahrenheit (1 to 3 degrees Celsius) above 1990 levels will produce beneficial impacts in some regions and harmful ones in others',\n",
              " ' Net annual costs will increase over time as global temperatures increase',\n",
              " '\\n\"Taken as a whole,\" the IPCC states, \"the range of published evidence indicates that the net damage costs of climate change are likely to be significant and to increase over time',\n",
              " '\\nScientists have studied past climate changes to understand the factors that can cause the planet to warm or cool',\n",
              " ' The big ones are changes in solar energy, ocean circulation, volcanic activity and the amount of greenhouse gases in the atmosphere',\n",
              " ' And they have each played a role at times',\n",
              " '\\nFor example, 300 years ago, a combination of reduced solar output and increased volcanic activity cooled parts of the planet enough that Londoners regularly ice skated on the Thames',\n",
              " ' About 12,000 years ago, major changes in Atlantic circulation plunged the Northern Hemisphere into a frigid state',\n",
              " ' And 56 million years ago, a giant burst of greenhouse gases, from volcanic activity or vast deposits of methane (or both), abruptly warmed the planet by at least 9 degrees Fahrenheit, scrambling the climate, choking the oceans and triggering mass extinctions',\n",
              " '\\nHere’s how it works: the planet’s temperature is basically a function of the energy the Earth absorbs from the sun (which heats it up) and the energy Earth emits to space as infrared radiation (which cools it down)',\n",
              " ' Because of their molecular structure, greenhouse gases temporarily absorb some of that outgoing infrared radiation and then re-emit it in all directions, sending some of that energy back toward the surface and heating the planet',\n",
              " ' Scientists have understood this process since the 1850s',\n",
              " '\\nToday, however, we are the ones causing CO2 levels to increase at an unprecedented pace by taking ancient carbon from geologic deposits of fossil fuels and putting it into the atmosphere when we burn them',\n",
              " ' Since 1750, carbon dioxide concentrations have increased by almost 50 percent',\n",
              " ' Methane and nitrous oxide, other important anthropogenic greenhouse gases that are released mainly by agricultural activities, have also spiked over the last 250 years',\n",
              " '\\nWe know based on the physics described above that this should cause the climate to warm',\n",
              " ' We also see certain telltale “fingerprints” of greenhouse warming',\n",
              " ' For example, nights are warming even faster than days because greenhouse gases don’t go away when the sun sets',\n",
              " ' And upper layers of the atmosphere have actually cooled, because more energy is being trapped by greenhouse gases in the lower atmosphere',\n",
              " '\\nA common source of confusion when it comes to climate change is the difference between weather and climate',\n",
              " ' Weather is the constantly changing set of meteorological conditions that we experience when we step outside, whereas climate is the long-term average of those conditions, usually calculated over a 30-year period',\n",
              " ' Or, as some say: Weather is your mood and climate is your personality',\n",
              " '\\nSo while 2 degrees Fahrenheit doesn’t represent a big change in the weather, it’s a huge change in climate',\n",
              " ' As we’ve already seen, it’s enough to melt ice and raise sea levels, to shift rainfall patterns around the world and to reorganize ecosystems, sending animals scurrying toward cooler habitats and killing trees by the millions',\n",
              " '\\nIt’s also important to remember that two degrees represents the global average, and many parts of the world have already warmed by more than that',\n",
              " ' For example, land areas have warmed about twice as much as the sea surface',\n",
              " ' And the Arctic has warmed by about 5 degrees',\n",
              " ' That’s because the loss of snow and ice at high latitudes allows the ground to absorb more energy, causing additional heating on top of greenhouse warming',\n",
              " '\\nRelatively small long-term changes in climate averages also shift extremes in significant ways',\n",
              " ' For instance, heat waves have always happened, but they have shattered records in recent years',\n",
              " ' In June of 2020, a town in Siberia registered temperatures of 100 degrees',\n",
              " ' And in Australia, meteorologists have added a new color to their weather maps to show areas where temperatures exceed 125 degrees',\n",
              " ' Rising sea levels have also increased the risk of flooding because of storm surges and high tides',\n",
              " ' These are the foreshocks of climate change',\n",
              " '\\nThe planet is warming, from North Pole to South Pole',\n",
              " ' Since 1906, the global average surface temperature has increased by more than 1',\n",
              " '6 degrees Fahrenheit (0',\n",
              " '9 degrees Celsius)—even more in sensitive polar regions',\n",
              " ' And the impacts of rising temperatures aren’t waiting for some far-flung future–the effects of global warming are appearing right now',\n",
              " ' The heat is melting glaciers and sea ice, shifting precipitation patterns, and setting animals on the move',\n",
              " '\\nMany people think of global warming and climate change as synonyms, but scientists prefer to use “climate change” when describing the complex shifts now affecting our planet’s weather and climate systems',\n",
              " ' Climate change encompasses not only rising average temperatures but also extreme weather events, shifting wildlife populations and habitats, rising seas, and a range of other impacts',\n",
              " ' All of these changes are emerging as humans continue to add heat-trapping greenhouse gases to the atmosphere',\n",
              " \"\\nEarth's atmosphere contains various gases that act as a blanket to trap heat from the sun and prevent it from escaping back into space\",\n",
              " ' This process is known as the greenhouse effect, and the gases are referred to as greenhouse gases',\n",
              " ' The main greenhouse gases that occur in nature are carbon dioxide, methane, and nitrous oxide',\n",
              " ' Without the greenhouse effect, the planet would be too cold to support life',\n",
              " \" Over time, the amount of greenhouse gases trapped in Earth's atmosphere has increased significantly, causing worldwide temperatures to rise\",\n",
              " '\\nNatural processes on Earth constantly create and destroy greenhouse gases',\n",
              " ' The decay of plant and animal matter, for example, produces carbon dioxide, which plants then absorb during photosynthesis',\n",
              " ' This natural cycle keeps the level of carbon dioxide in the atmosphere fairly stable',\n",
              " \" Shifts in the planet's crust and changes in ocean patterns impact weather, as do fluctuations in the sun's output of radiation\",\n",
              " ' Volcanic activity also affects the climate because eruptions discharge greenhouse gases and other pollutants into the atmosphere',\n",
              " \" Climate change scientists at the National Aeronautics and Space Administration (NASA) and other federal and international agencies recognize that these natural factors continue to play a role in climate change but contend that the impact of these factors alone does not explain the substantial rise in Earth's temperature\",\n",
              " ' Natural causes of climate change are referred to as naturogenic, while human-made causes of climate change are referred to as anthropogenic',\n",
              " \"\\nEarth's vegetation releases and absorbs more than two hundred billion metric tons of carbon dioxide annually\",\n",
              " ' Human activities, such as the burning of fossil fuels, add an extra seven billion metric tons per year',\n",
              " ' Over time, these additions have had a dramatic effect on the atmosphere',\n",
              " ' In the past 150 years, the concentration of carbon dioxide in the atmosphere has risen by more than 30 percent',\n",
              " ' Deforestation has also played a role in this increase by eliminating forests that would otherwise absorb tons of carbon dioxide',\n",
              " '\\nIncreased levels of other greenhouse gases such as nitrous oxide and methane have also resulted from human activities',\n",
              " ' Several agricultural and industrial activities, such as the use of certain fertilizers in agriculture, produce nitrous oxide',\n",
              " ' Methane emissions come from the production of fossil fuels, from landfills, and from livestock',\n",
              " \" These gases may cause even more harm than carbon dioxide, even though less of them exist, because they have a much greater effect per pound on Earth's temperature\",\n",
              " ' Methane, for example, is a greenhouse gas that is twenty-one times as potent as carbon dioxide',\n",
              " ' Beginning in October 2015, a methane gas leak from a California storage facility vented about five billion cubic feet of gas into the atmosphere',\n",
              " ' The leak took more than three months to seal and was finally capped on February 18, 2016',\n",
              " ' The incident constituted the largest accidental discharge of greenhouse gases in US history, releasing the equivalent of the yearly exhaust emissions from 572,000 automobiles',\n",
              " '\\nHumans have created and released greenhouse gases that do not occur in nature',\n",
              " ' These include hydrofluorocarbons (HFCs), perfluorocarbons (PFCs), and sulfur hexafluoride (SF6)',\n",
              " \" These gases, released during such industrial processes as aluminum production and electrical transmission, have thousands of times greater effect on the planet's temperature than carbon dioxide\",\n",
              " '\\nClimate science measures changes that occur to a large geographical area over a long period of time, making it difficult to provide definitive answers to climate change questions',\n",
              " ' However, multiple studies have been conducted since the 1990s to determine how the scientific community collectively views anthropogenic climate change',\n",
              " ' These studies included surveys as well as analyses of peer-reviewed articles and have concluded that at least 97 percent of actively publishing climate scientists around the world agree that human activities have contributed to rising global temperatures',\n",
              " '\\nThough surveys indicate that many Americans remain skeptical toward arguments and evidence put forth by climate scientists, reports suggest that belief in global warming has grown steadily in the twenty-first century',\n",
              " \" According to annual polls conducted by Gallup, the public's belief that global warming is caused by human activity, that climate change has begun to take effect, and that global warming will soon pose a serious threat has increased since 2001\",\n",
              " \" Researchers have observed a strong correlation between people's political affiliations and their levels of concern regarding global warming and acceptance of climate science\",\n",
              " ' A total of 64 percent of all Americans polled reported a belief that human activity contributes to global warming in 2018, which included 89 percent of Democrats, 62 percent of independents, and 35 percent of Republicans',\n",
              " ' Similarly, 91 percent of Democrats responded that they worried significantly about global warming, compared to 62 percent of independents and 33 percent of Republicans',\n",
              " ' Democrats also reported much higher confidence (86 percent) that scientists have reached a consensus that global warming is real than Republicans (42 percent)',\n",
              " \" Gallup's polling further indicates that people age 55 and older are more likely than younger respondents to believe that the media exaggerates the threat of climate change\",\n",
              " '\\nSkeptics of global warming and climate change have noted that Earth has experienced cyclical changes to its climate patterns for millennia and that recent climatic shifts are not as severe as indicated or necessarily a consequence of human activity alone',\n",
              " ' Climate scientists contend that such skepticism may stem from an unwillingness to face the scope of the threat posed to the planet by human activity',\n",
              " ' Additionally, conservative donors, including several foundations established by wealthy families, have contributed large amounts of money to organizations that promote climate change denial',\n",
              " ' Foundations linked to the prominent Koch family, for example, donated over $100 million to such organizations between 1997 and 2015, as reported by the environmental organization Greenpeace',\n",
              " '\\nEven if all members of society agreed that global temperatures are rising and humans are the cause, the challenges created by climate change lack an obvious solution',\n",
              " ' No climate model formulated by scientists to chart climate patterns has had 100 percent accuracy in predicting changes',\n",
              " ' However, scientists continue to refine their methods to produce more reliable data',\n",
              " ' Most climate models failed to predict a slowdown in rising temperatures at the beginning of the twenty-first century',\n",
              " ' Some predictions have also underestimated threats',\n",
              " ' In its initial assessment of rising sea levels in 1990, the Intergovernmental Panel on Climate Change (IPCC) originally anticipated a sea level rise of 1',\n",
              " '9 millimeters per year from that year onward',\n",
              " ' However, studies by NASA have revealed that sea levels have in fact risen at a rate of 3',\n",
              " '2 millimeters per year',\n",
              " ' The science of climate change is so complex that some actions that seem helpful may cause damage in the long term',\n",
              " ' Some of the most potent greenhouse gases, HFCs and PFCs, are commonly used as replacements for other chemicals called chlorofluorocarbons (CFCs), which were phased out between 1989 and 1996 because they damaged the ozone layer',\n",
              " ' Consequently, the same process that solved one environmental problem—ozone damage—contributed to another',\n",
              " '\\nThe consequences of global warming remain an issue of great debate and uncertainty, and some researchers predict dramatic and serious problems for future generations',\n",
              " ' Warmer oceans could result in stronger and more frequent hurricanes',\n",
              " ' As temperatures climb, some regions could experience frequent heat waves and devastating droughts and wildfires',\n",
              " ' During the 1990s and first decade of the twenty-first century, many areas in the United States endured record-breaking heat and drought',\n",
              " ' In 2012, severe drought plagued the Wheat Belt of the United States, located in the North American Great Plains',\n",
              " ' In the beginning of 2013, Australia experienced a heat wave that caused hundreds of wildfires throughout the country',\n",
              " ' Climate change has also been linked to the severe drought that occurred in California between 2011 and early 2017',\n",
              " ' In 2018 California has further endured massive wildfires that have led to the displacement of thousands of residents, widespread destruction of property, and the deaths of at least eight people',\n",
              " ' Scientists have attributed the fires, which included the largest wildfire in California history to date, to the presence of extremely dry vegetation, brought on by rising temperatures, that created conditions that allowed the fires to spread rapidly and burn intensely',\n",
              " ' California governor Jerry Brown lamented that such fires have become increasingly common in the southwestern United States and warned that fires would likely become more intense as climate change continues',\n",
              " '\\nMany coastal areas around the world could also face severe flooding due to rising sea levels',\n",
              " ' Low-lying islands in the Pacific Ocean would eventually become uninhabitable',\n",
              " ' Within the past century, sea level has risen by four to eight inches worldwide',\n",
              " ' Some of these effects were felt in 2012 when a super storm known as Superstorm Sandy hit the Eastern coast of the United States, and a typhoon in the Philippines claimed the lives of more than one thousand people',\n",
              " ' The hurricane season of 2017 proved to be the costliest hurricane season since 1900, with severe weather and rising sea levels leading to tragic loss of life and over $215 billion of property damage in Florida, Texas, and Puerto Rico as well as other states in the Southeast and several countries located in Central America and the Caribbean',\n",
              " '\\nGlobal warming could also have a major impact on habitats',\n",
              " ' Some areas well suited to farming might become too dry or too wet to support agriculture',\n",
              " ' Long periods of drought could turn fertile lands into deserts with little vegetation',\n",
              " ' Plants and animals might not be able to survive the rapid changes caused by global warming and could become extinct',\n",
              " ' Over the long term, such changes would result in a loss of biodiversity on the planet',\n",
              " ' Some ecosystems, such as coral reefs and coastal mangrove swamps, are likely to disappear completely']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "xXFtRDHpobtl",
        "outputId": "affd3637-0f45-48d4-ded1-48eb56d33304"
      },
      "source": [
        "new_df = []\n",
        "\n",
        "for new in vlad_sentences:\n",
        "  new_df.append({'Sentence':new, 'Label':'neural network art'})\n",
        "\n",
        "for new in ks_sentences:\n",
        "  new_df.append({'Sentence':new, 'Label':'climate change'})\n",
        "\n",
        "for new in artem_sentences:\n",
        "  new_df.append({'Sentence':new, 'Label':'neural network recognition'})\n",
        "\n",
        "new_df = pd.DataFrame(data=new_df, columns=['Sentence', 'Label'])\n",
        "\n",
        "new_df['Target'] = new_df['Label']\n",
        "new_df.replace({'Target':{'neural network art':1, 'climate change':0, 'neural network recognition':0}}, inplace=True)\n",
        "new_df"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Label</th>\n",
              "      <th>Target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>In the past few years, many artists have begun...</td>\n",
              "      <td>neural network art</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\\nIn computer vision and perceptual psychology...</td>\n",
              "      <td>neural network art</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\\nIn other words, modern neural models lend th...</td>\n",
              "      <td>neural network art</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\\nThe most prominent tool in neural art at the...</td>\n",
              "      <td>neural network art</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\\nGiven a large collection of images of a spec...</td>\n",
              "      <td>neural network art</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>302</th>\n",
              "      <td>\\nIn May 2017, a man was arrested using an aut...</td>\n",
              "      <td>neural network recognition</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>303</th>\n",
              "      <td>[68] Live facial recognition has been trialled...</td>\n",
              "      <td>neural network recognition</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>304</th>\n",
              "      <td>[69] In August 2020 the Court of Appeal ruled ...</td>\n",
              "      <td>neural network recognition</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>305</th>\n",
              "      <td>S</td>\n",
              "      <td>neural network recognition</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>306</th>\n",
              "      <td>Department of State operates one of the large...</td>\n",
              "      <td>neural network recognition</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>307 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              Sentence  ... Target\n",
              "0    In the past few years, many artists have begun...  ...      1\n",
              "1    \\nIn computer vision and perceptual psychology...  ...      1\n",
              "2    \\nIn other words, modern neural models lend th...  ...      1\n",
              "3    \\nThe most prominent tool in neural art at the...  ...      1\n",
              "4    \\nGiven a large collection of images of a spec...  ...      1\n",
              "..                                                 ...  ...    ...\n",
              "302  \\nIn May 2017, a man was arrested using an aut...  ...      0\n",
              "303  [68] Live facial recognition has been trialled...  ...      0\n",
              "304  [69] In August 2020 the Court of Appeal ruled ...  ...      0\n",
              "305                                                  S  ...      0\n",
              "306   Department of State operates one of the large...  ...      0\n",
              "\n",
              "[307 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFPE5M_LzQQa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f770f401-257f-48ed-9352-d993e65201a9"
      },
      "source": [
        "# vectorization of text\n",
        "max_tokens = 10000\n",
        "\n",
        "sentences = vlad_sentences+artem_sentences+ks_sentences\n",
        "tokens_count = 0\n",
        "for new in sentences:\n",
        "  tokens_count+=len(new.split())\n",
        "avg_tokens = round(tokens_count/len(sentences))\n",
        "avg_tokens"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fm1gjy-eUHB4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4f2b57a-aa30-4438-86d7-ac2a2aaa1994"
      },
      "source": [
        "#tokenization and embedding\n",
        "text_vectorizer = TextVectorization(max_tokens=max_tokens, \n",
        "                                    standardize=\"lower_and_strip_punctuation\", \n",
        "                                    split=\"whitespace\", \n",
        "                                    ngrams=None, \n",
        "                                    output_mode=\"int\",\n",
        "                                    output_sequence_length=avg_tokens, \n",
        "                                    pad_to_max_tokens=True)\n",
        "\n",
        "text_vectorizer.adapt(new_df['Sentence'])\n",
        "\n",
        "text_vectorizer(new_df['Sentence'])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(307, 25), dtype=int64, numpy=\n",
              "array([[   6,    2,  212, ...,  826,    6, 1800],\n",
              "       [   6,  303,  328, ...,    0,    0,    0],\n",
              "       [   6,   62,  325, ...,  139,  455,  266],\n",
              "       ...,\n",
              "       [2051,    6, 1943, ...,  251,  101,    6],\n",
              "       [ 575,    0,    0, ...,    0,    0,    0],\n",
              "       [ 763,    3,  363, ...,   24,  102,  524]])>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64764Hn5z7TU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7fd692c-3af4-495b-c65e-79ee561a5eb1"
      },
      "source": [
        "print(f\"Most Used: {text_vectorizer.get_vocabulary()[:5]}\")\n",
        "print(f\"Most Unused: {text_vectorizer.get_vocabulary()[-5:]}\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most Used: ['', '[UNK]', 'the', 'of', 'to']\n",
            "Most Unused: ['125', '12000', '117', '10', '0']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HsUT7y2avSdJ",
        "outputId": "7a2a11f7-6692-4d58-b525-447e2a56a254"
      },
      "source": [
        "embedding = layers.Embedding(input_dim=max_tokens, # set input shape\n",
        "                             output_dim=128, # set size of embedding vector\n",
        "                             embeddings_initializer=\"uniform\", # default, intialize randomly\n",
        "                             input_length=avg_tokens) # how long is each input\n",
        "\n",
        "embedding(text_vectorizer(new_df['Sentence']))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(307, 25, 128), dtype=float32, numpy=\n",
              "array([[[-0.02749467, -0.01595894, -0.03922828, ...,  0.02976247,\n",
              "          0.02037157,  0.00302383],\n",
              "        [-0.03265711, -0.03129109, -0.0354785 , ...,  0.02647159,\n",
              "         -0.01067201, -0.04187087],\n",
              "        [ 0.02307943, -0.02446737, -0.04502044, ..., -0.02807719,\n",
              "         -0.03352444, -0.00244167],\n",
              "        ...,\n",
              "        [-0.03057656,  0.04549277,  0.03021098, ..., -0.00366615,\n",
              "         -0.02244839, -0.00055165],\n",
              "        [-0.02749467, -0.01595894, -0.03922828, ...,  0.02976247,\n",
              "          0.02037157,  0.00302383],\n",
              "        [-0.02698604, -0.00293987, -0.0318244 , ..., -0.02749285,\n",
              "          0.00856367,  0.00073034]],\n",
              "\n",
              "       [[-0.02749467, -0.01595894, -0.03922828, ...,  0.02976247,\n",
              "          0.02037157,  0.00302383],\n",
              "        [ 0.00381104,  0.03898697,  0.04099632, ...,  0.0400547 ,\n",
              "         -0.046062  ,  0.02598841],\n",
              "        [ 0.0170255 ,  0.01099968,  0.03378505, ...,  0.02919859,\n",
              "         -0.04416387,  0.00369433],\n",
              "        ...,\n",
              "        [-0.0477112 ,  0.04038603,  0.02235092, ..., -0.00516093,\n",
              "          0.0288532 ,  0.03812705],\n",
              "        [-0.0477112 ,  0.04038603,  0.02235092, ..., -0.00516093,\n",
              "          0.0288532 ,  0.03812705],\n",
              "        [-0.0477112 ,  0.04038603,  0.02235092, ..., -0.00516093,\n",
              "          0.0288532 ,  0.03812705]],\n",
              "\n",
              "       [[-0.02749467, -0.01595894, -0.03922828, ...,  0.02976247,\n",
              "          0.02037157,  0.00302383],\n",
              "        [-0.02429303, -0.03257952,  0.03914297, ..., -0.02520515,\n",
              "          0.04592956,  0.01465991],\n",
              "        [-0.03236586, -0.03008705, -0.04583227, ...,  0.01029943,\n",
              "         -0.01426594, -0.00423716],\n",
              "        ...,\n",
              "        [ 0.00476317, -0.01724301,  0.04406543, ...,  0.0387595 ,\n",
              "          0.01442832,  0.0419047 ],\n",
              "        [-0.04194896, -0.04717323, -0.00857949, ..., -0.02038289,\n",
              "         -0.03952463,  0.04047236],\n",
              "        [ 0.03579411,  0.00194641,  0.02462574, ..., -0.04184153,\n",
              "         -0.00867332, -0.04087093]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[ 0.01097403,  0.02207393, -0.01325173, ...,  0.03269959,\n",
              "          0.04695577, -0.04650357],\n",
              "        [-0.02749467, -0.01595894, -0.03922828, ...,  0.02976247,\n",
              "          0.02037157,  0.00302383],\n",
              "        [-0.04515574, -0.03704462,  0.02663622, ...,  0.03837853,\n",
              "         -0.00104762,  0.01340089],\n",
              "        ...,\n",
              "        [-0.03709307, -0.02432604,  0.03081513, ...,  0.00060769,\n",
              "         -0.00483445, -0.01459167],\n",
              "        [ 0.01283402,  0.04819182, -0.04366292, ..., -0.04701957,\n",
              "          0.0141337 ,  0.04555502],\n",
              "        [-0.02749467, -0.01595894, -0.03922828, ...,  0.02976247,\n",
              "          0.02037157,  0.00302383]],\n",
              "\n",
              "       [[ 0.04327163, -0.02669668, -0.02279316, ..., -0.03322048,\n",
              "         -0.00076117, -0.00814873],\n",
              "        [-0.0477112 ,  0.04038603,  0.02235092, ..., -0.00516093,\n",
              "          0.0288532 ,  0.03812705],\n",
              "        [-0.0477112 ,  0.04038603,  0.02235092, ..., -0.00516093,\n",
              "          0.0288532 ,  0.03812705],\n",
              "        ...,\n",
              "        [-0.0477112 ,  0.04038603,  0.02235092, ..., -0.00516093,\n",
              "          0.0288532 ,  0.03812705],\n",
              "        [-0.0477112 ,  0.04038603,  0.02235092, ..., -0.00516093,\n",
              "          0.0288532 ,  0.03812705],\n",
              "        [-0.0477112 ,  0.04038603,  0.02235092, ..., -0.00516093,\n",
              "          0.0288532 ,  0.03812705]],\n",
              "\n",
              "       [[-0.01981362,  0.02834656, -0.02904918, ..., -0.0009896 ,\n",
              "         -0.02475265, -0.01829095],\n",
              "        [-0.02043363,  0.01998652, -0.02358526, ..., -0.00269552,\n",
              "          0.03923967, -0.01529403],\n",
              "        [-0.03782286, -0.02837869, -0.0210142 , ...,  0.00984665,\n",
              "          0.01097312, -0.02700044],\n",
              "        ...,\n",
              "        [-0.04803406,  0.00717099,  0.01263389, ...,  0.0232668 ,\n",
              "          0.02032484, -0.00331044],\n",
              "        [-0.01645405,  0.04384675,  0.01125103, ...,  0.01281278,\n",
              "          0.04909743,  0.036295  ],\n",
              "        [ 0.02230569, -0.00393611, -0.01745393, ...,  0.03987881,\n",
              "          0.04990354,  0.04756948]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7L-Q1oaDVZLw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "afd09e6e-8011-4ef9-c299-4d7019d0486f"
      },
      "source": [
        "# import libraries\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_split, test_split = train_test_split(new_df, train_size=0.8, test_size=0.2)\n",
        "train_split"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Label</th>\n",
              "      <th>Target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>304</th>\n",
              "      <td>[69] In August 2020 the Court of Appeal ruled ...</td>\n",
              "      <td>neural network recognition</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>156</th>\n",
              "      <td>And the impacts of rising temperatures aren’t...</td>\n",
              "      <td>climate change</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>206</th>\n",
              "      <td>Most climate models failed to predict a slowd...</td>\n",
              "      <td>climate change</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>272</th>\n",
              "      <td>\\nRecognize and manipulate faces from Python o...</td>\n",
              "      <td>neural network recognition</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>217</th>\n",
              "      <td>As temperatures climb, some regions could exp...</td>\n",
              "      <td>climate change</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>183</th>\n",
              "      <td>Beginning in October 2015, a methane gas leak...</td>\n",
              "      <td>climate change</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82</th>\n",
              "      <td>\\nThree datasets of digital images of painting...</td>\n",
              "      <td>neural network art</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>252</th>\n",
              "      <td>\\nIn the coming weeks, Meta will shut down the...</td>\n",
              "      <td>neural network recognition</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>305</th>\n",
              "      <td>S</td>\n",
              "      <td>neural network recognition</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>184</th>\n",
              "      <td>The leak took more than three months to seal ...</td>\n",
              "      <td>climate change</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>245 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              Sentence  ... Target\n",
              "304  [69] In August 2020 the Court of Appeal ruled ...  ...      0\n",
              "156   And the impacts of rising temperatures aren’t...  ...      0\n",
              "206   Most climate models failed to predict a slowd...  ...      0\n",
              "272  \\nRecognize and manipulate faces from Python o...  ...      0\n",
              "217   As temperatures climb, some regions could exp...  ...      0\n",
              "..                                                 ...  ...    ...\n",
              "183   Beginning in October 2015, a methane gas leak...  ...      0\n",
              "82   \\nThree datasets of digital images of painting...  ...      1\n",
              "252  \\nIn the coming weeks, Meta will shut down the...  ...      0\n",
              "305                                                  S  ...      0\n",
              "184   The leak took more than three months to seal ...  ...      0\n",
              "\n",
              "[245 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIu3Fp7fttP0"
      },
      "source": [
        "#import libraries for classification\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "def calculate_results(y_true, y_pred):\n",
        "  \"\"\"\n",
        "  Calculates model accuracy, precision, recall and f1 score of a binary classification model.\n",
        "\n",
        "  Args:\n",
        "  -----\n",
        "  y_true = true labels in the form of a 1D array\n",
        "  y_pred = predicted labels in the form of a 1D array\n",
        "\n",
        "  Returns a dictionary of accuracy, precision, recall, f1-score.\n",
        "  \"\"\"\n",
        "  # Calculate model accuracy\n",
        "  model_accuracy = accuracy_score(y_true, y_pred) * 100\n",
        "  # Calculate model precision, recall and f1 score using \"weighted\" average\n",
        "  model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
        "  model_results = {\"accuracy\": model_accuracy,\n",
        "                  \"precision\": model_precision,\n",
        "                  \"recall\": model_recall,\n",
        "                  \"f1\": model_f1}\n",
        "  return model_results\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wj0nNYBawDAF",
        "outputId": "e2e875b1-b591-42fc-d9a8-5e96916b1067"
      },
      "source": [
        "#import libraries for Naive Bayes Model\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Create tokenization and modelling pipeline\n",
        "model_0 = Pipeline([\n",
        "                    (\"tfidf\", TfidfVectorizer()), # convert words to numbers using tfidf\n",
        "                    (\"clf\", MultinomialNB()) # model the text\n",
        "])\n",
        "\n",
        "# Fit the pipeline to the training data\n",
        "model_0.fit(train_split['Sentence'], train_split['Target'])\n",
        "baseline_score = model_0.score(test_split['Sentence'], test_split['Target'])\n",
        "print(f\"Baseline model accuracy is: {baseline_score*100:.2f}%\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline model accuracy is: 93.55%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nxhiUqxUHSM"
      },
      "source": [
        "#dense neural network\n",
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\") # inputs are 1-dimensional strings\n",
        "x = text_vectorizer(inputs) # turn the input text into numbers\n",
        "x = embedding(x) # create an embedding of the numerized numbers\n",
        "x = layers.GlobalAveragePooling1D()(x) # lower the dimensionality of the embedding (try running the model without this layer and see what happens)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x) # create the output layer, want binary outputs so use sigmoid activation\n",
        "model_1 = tf.keras.Model(inputs, outputs, name=\"model_1_dense\") # construct the model\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fdp49g8cv7KY",
        "outputId": "48753dec-a800-4026-daf3-71b6b36d8d53"
      },
      "source": [
        "model_1.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "model_1.summary()\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1_dense\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization (TextVec  (None, 25)               0         \n",
            " torization)                                                     \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 25, 128)           1280000   \n",
            "                                                                 \n",
            " global_average_pooling1d (G  (None, 128)              0         \n",
            " lobalAveragePooling1D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,280,129\n",
            "Trainable params: 1,280,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FIW9jifdv-ra",
        "outputId": "02830150-8ef6-4818-a779-6c6dbd6c4980"
      },
      "source": [
        "# Fit the model\n",
        "model_1_history = model_1.fit(train_split['Sentence'], # input sentences can be a list of strings due to text preprocessing layer built-in model\n",
        "                              train_split['Target'],\n",
        "                              epochs=50,\n",
        "                              validation_data=(test_split['Sentence'], test_split['Target']))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "8/8 [==============================] - 2s 47ms/step - loss: 0.6877 - accuracy: 0.6000 - val_loss: 0.6785 - val_accuracy: 0.6613\n",
            "Epoch 2/50\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.6669 - accuracy: 0.7224 - val_loss: 0.6632 - val_accuracy: 0.6774\n",
            "Epoch 3/50\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.6471 - accuracy: 0.7184 - val_loss: 0.6476 - val_accuracy: 0.6774\n",
            "Epoch 4/50\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.6258 - accuracy: 0.7347 - val_loss: 0.6315 - val_accuracy: 0.6774\n",
            "Epoch 5/50\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.6037 - accuracy: 0.7551 - val_loss: 0.6147 - val_accuracy: 0.6774\n",
            "Epoch 6/50\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.5794 - accuracy: 0.7755 - val_loss: 0.5977 - val_accuracy: 0.6774\n",
            "Epoch 7/50\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.5540 - accuracy: 0.7918 - val_loss: 0.5805 - val_accuracy: 0.6774\n",
            "Epoch 8/50\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.5286 - accuracy: 0.8122 - val_loss: 0.5631 - val_accuracy: 0.7097\n",
            "Epoch 9/50\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.5021 - accuracy: 0.8245 - val_loss: 0.5458 - val_accuracy: 0.7581\n",
            "Epoch 10/50\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.4764 - accuracy: 0.8531 - val_loss: 0.5289 - val_accuracy: 0.7581\n",
            "Epoch 11/50\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.4498 - accuracy: 0.8653 - val_loss: 0.5122 - val_accuracy: 0.7742\n",
            "Epoch 12/50\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.4230 - accuracy: 0.8776 - val_loss: 0.4953 - val_accuracy: 0.8065\n",
            "Epoch 13/50\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.3974 - accuracy: 0.8857 - val_loss: 0.4778 - val_accuracy: 0.8548\n",
            "Epoch 14/50\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.3713 - accuracy: 0.8939 - val_loss: 0.4604 - val_accuracy: 0.8548\n",
            "Epoch 15/50\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.3459 - accuracy: 0.9143 - val_loss: 0.4431 - val_accuracy: 0.8710\n",
            "Epoch 16/50\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.3212 - accuracy: 0.9265 - val_loss: 0.4263 - val_accuracy: 0.8710\n",
            "Epoch 17/50\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.2977 - accuracy: 0.9388 - val_loss: 0.4097 - val_accuracy: 0.8871\n",
            "Epoch 18/50\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.2753 - accuracy: 0.9469 - val_loss: 0.3934 - val_accuracy: 0.9032\n",
            "Epoch 19/50\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.2538 - accuracy: 0.9592 - val_loss: 0.3778 - val_accuracy: 0.9032\n",
            "Epoch 20/50\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.2344 - accuracy: 0.9755 - val_loss: 0.3631 - val_accuracy: 0.9032\n",
            "Epoch 21/50\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.2160 - accuracy: 0.9837 - val_loss: 0.3491 - val_accuracy: 0.9032\n",
            "Epoch 22/50\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.1995 - accuracy: 0.9837 - val_loss: 0.3359 - val_accuracy: 0.9032\n",
            "Epoch 23/50\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.1837 - accuracy: 0.9878 - val_loss: 0.3234 - val_accuracy: 0.9194\n",
            "Epoch 24/50\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.1699 - accuracy: 0.9878 - val_loss: 0.3117 - val_accuracy: 0.9194\n",
            "Epoch 25/50\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.1570 - accuracy: 0.9878 - val_loss: 0.3010 - val_accuracy: 0.9194\n",
            "Epoch 26/50\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.1457 - accuracy: 0.9878 - val_loss: 0.2906 - val_accuracy: 0.9194\n",
            "Epoch 27/50\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.1351 - accuracy: 0.9918 - val_loss: 0.2811 - val_accuracy: 0.9194\n",
            "Epoch 28/50\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.1255 - accuracy: 0.9959 - val_loss: 0.2724 - val_accuracy: 0.9194\n",
            "Epoch 29/50\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.1170 - accuracy: 0.9959 - val_loss: 0.2643 - val_accuracy: 0.9194\n",
            "Epoch 30/50\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.1091 - accuracy: 0.9959 - val_loss: 0.2567 - val_accuracy: 0.9194\n",
            "Epoch 31/50\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.1021 - accuracy: 0.9959 - val_loss: 0.2494 - val_accuracy: 0.9516\n",
            "Epoch 32/50\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0958 - accuracy: 0.9959 - val_loss: 0.2425 - val_accuracy: 0.9516\n",
            "Epoch 33/50\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0896 - accuracy: 0.9959 - val_loss: 0.2365 - val_accuracy: 0.9516\n",
            "Epoch 34/50\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0843 - accuracy: 0.9959 - val_loss: 0.2309 - val_accuracy: 0.9516\n",
            "Epoch 35/50\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0795 - accuracy: 0.9959 - val_loss: 0.2257 - val_accuracy: 0.9516\n",
            "Epoch 36/50\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0751 - accuracy: 0.9959 - val_loss: 0.2202 - val_accuracy: 0.9516\n",
            "Epoch 37/50\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0709 - accuracy: 0.9959 - val_loss: 0.2153 - val_accuracy: 0.9516\n",
            "Epoch 38/50\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0672 - accuracy: 0.9959 - val_loss: 0.2108 - val_accuracy: 0.9516\n",
            "Epoch 39/50\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0637 - accuracy: 0.9959 - val_loss: 0.2064 - val_accuracy: 0.9516\n",
            "Epoch 40/50\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0605 - accuracy: 0.9959 - val_loss: 0.2019 - val_accuracy: 0.9516\n",
            "Epoch 41/50\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0576 - accuracy: 0.9959 - val_loss: 0.1977 - val_accuracy: 0.9516\n",
            "Epoch 42/50\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0548 - accuracy: 0.9959 - val_loss: 0.1941 - val_accuracy: 0.9516\n",
            "Epoch 43/50\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0524 - accuracy: 0.9959 - val_loss: 0.1904 - val_accuracy: 0.9516\n",
            "Epoch 44/50\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0499 - accuracy: 0.9959 - val_loss: 0.1871 - val_accuracy: 0.9516\n",
            "Epoch 45/50\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0477 - accuracy: 0.9959 - val_loss: 0.1840 - val_accuracy: 0.9516\n",
            "Epoch 46/50\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0458 - accuracy: 0.9959 - val_loss: 0.1815 - val_accuracy: 0.9516\n",
            "Epoch 47/50\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0439 - accuracy: 0.9959 - val_loss: 0.1786 - val_accuracy: 0.9516\n",
            "Epoch 48/50\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0421 - accuracy: 0.9959 - val_loss: 0.1761 - val_accuracy: 0.9516\n",
            "Epoch 49/50\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0405 - accuracy: 0.9959 - val_loss: 0.1727 - val_accuracy: 0.9677\n",
            "Epoch 50/50\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0388 - accuracy: 0.9959 - val_loss: 0.1701 - val_accuracy: 0.9677\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ROXko56mUHgl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4093ff31-c88d-466a-c05e-f4fda15ed2eb"
      },
      "source": [
        "#compare model effectiveness\n",
        "calculate_results(test_split['Target'], model_0.predict(test_split['Sentence']))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 93.54838709677419,\n",
              " 'f1': 0.9335886603229755,\n",
              " 'precision': 0.9412186379928316,\n",
              " 'recall': 0.9354838709677419}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kzWiyKslihDP",
        "outputId": "6cc211e4-6d02-4b46-c91a-ddb04f1fad02"
      },
      "source": [
        "calculate_results(test_split['Target'], tf.squeeze(tf.round(model_1.predict(test_split['Sentence']))))\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 96.7741935483871,\n",
              " 'f1': 0.9673195084485408,\n",
              " 'precision': 0.9692423105776444,\n",
              " 'recall': 0.967741935483871}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    }
  ]
}