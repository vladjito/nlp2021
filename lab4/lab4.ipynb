{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lab4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "3suJfqw4OdIB"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf, requests as rqst, io\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "rnd = np.random.randint"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CpfL4lOIIU0x",
        "outputId": "7ef1c6c2-eff7-4177-b52a-d7e96e7dce24"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1bwxXcKUAgf"
      },
      "source": [
        "#create the grouped dataset based on the data from each participant\n",
        "vlad_file = open(\"/content/drive/MyDrive/NLP/datavlad.txt\")\n",
        "vlad_sentences = vlad_file.read().split('.')[:-1]\n",
        "\n",
        "artem_file = open(\"/content/drive/MyDrive/NLP/dataartem.txt\")\n",
        "artem_sentences = artem_file.read().split('.')[:-1]\n",
        "\n",
        "ks_file = open(\"/content/drive/MyDrive/NLP/dataks.txt\")\n",
        "ks_sentences = ks_file.read().split('.')[:-1]"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "xXFtRDHpobtl",
        "outputId": "596d4101-a32b-4db1-b402-72f456ebd052"
      },
      "source": [
        "new_df = []\n",
        "\n",
        "for new in vlad_sentences:\n",
        "  new_df.append({'Sentence':new, 'Label':'neural network art'})\n",
        "\n",
        "for new in ks_sentences:\n",
        "  new_df.append({'Sentence':new, 'Label':'climate change'})\n",
        "\n",
        "for new in artem_sentences:\n",
        "  new_df.append({'Sentence':new, 'Label':'neural network recognition'})\n",
        "\n",
        "new_df = pd.DataFrame(data=new_df, columns=['Sentence', 'Label'])\n",
        "\n",
        "new_df['Target'] = new_df['Label']\n",
        "new_df.replace({'Target':{'neural network art':1, 'climate change':0, 'neural network recognition':0}}, inplace=True)\n",
        "new_df"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Label</th>\n",
              "      <th>Target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>In the past few years, many artists have begun...</td>\n",
              "      <td>neural network art</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\\nIn computer vision and perceptual psychology...</td>\n",
              "      <td>neural network art</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\\nIn other words, modern neural models lend th...</td>\n",
              "      <td>neural network art</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\\nThe most prominent tool in neural art at the...</td>\n",
              "      <td>neural network art</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\\nGiven a large collection of images of a spec...</td>\n",
              "      <td>neural network art</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>302</th>\n",
              "      <td>\\nIn May 2017, a man was arrested using an aut...</td>\n",
              "      <td>neural network recognition</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>303</th>\n",
              "      <td>[68] Live facial recognition has been trialled...</td>\n",
              "      <td>neural network recognition</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>304</th>\n",
              "      <td>[69] In August 2020 the Court of Appeal ruled ...</td>\n",
              "      <td>neural network recognition</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>305</th>\n",
              "      <td>S</td>\n",
              "      <td>neural network recognition</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>306</th>\n",
              "      <td>Department of State operates one of the large...</td>\n",
              "      <td>neural network recognition</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>307 rows Ã— 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              Sentence  ... Target\n",
              "0    In the past few years, many artists have begun...  ...      1\n",
              "1    \\nIn computer vision and perceptual psychology...  ...      1\n",
              "2    \\nIn other words, modern neural models lend th...  ...      1\n",
              "3    \\nThe most prominent tool in neural art at the...  ...      1\n",
              "4    \\nGiven a large collection of images of a spec...  ...      1\n",
              "..                                                 ...  ...    ...\n",
              "302  \\nIn May 2017, a man was arrested using an aut...  ...      0\n",
              "303  [68] Live facial recognition has been trialled...  ...      0\n",
              "304  [69] In August 2020 the Court of Appeal ruled ...  ...      0\n",
              "305                                                  S  ...      0\n",
              "306   Department of State operates one of the large...  ...      0\n",
              "\n",
              "[307 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RmSlaX2DJzM"
      },
      "source": [
        "# vectorization of text\n",
        "max_tokens = 10000\n",
        "\n",
        "sentences = vlad_sentences+artem_sentences+ks_sentences\n",
        "tokens_count = 0\n",
        "for new in sentences:\n",
        "  tokens_count+=len(new.split())\n",
        "avg_tokens = round(tokens_count/len(sentences))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fm1gjy-eUHB4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47c1f7a8-eca5-4e0f-9279-794661ada5bc"
      },
      "source": [
        "#tokenization and embedding\n",
        "text_vectorizer = TextVectorization(max_tokens=max_tokens, \n",
        "                                    standardize=\"lower_and_strip_punctuation\", \n",
        "                                    split=\"whitespace\", \n",
        "                                    ngrams=None, \n",
        "                                    output_mode=\"int\",\n",
        "                                    output_sequence_length=avg_tokens, \n",
        "                                    pad_to_max_tokens=True)\n",
        "\n",
        "text_vectorizer.adapt(new_df['Sentence'])\n",
        "\n",
        "text_vectorizer(new_df['Sentence'])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(307, 25), dtype=int64, numpy=\n",
              "array([[   6,    2,  212, ...,  826,    6, 1800],\n",
              "       [   6,  303,  328, ...,    0,    0,    0],\n",
              "       [   6,   62,  325, ...,  139,  455,  266],\n",
              "       ...,\n",
              "       [2051,    6, 1943, ...,  251,  101,    6],\n",
              "       [ 575,    0,    0, ...,    0,    0,    0],\n",
              "       [ 763,    3,  363, ...,   24,  102,  524]])>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HsUT7y2avSdJ",
        "outputId": "80a0b8d8-53ed-4c72-fb78-91655dd50b81"
      },
      "source": [
        "embedding = layers.Embedding(input_dim=max_tokens, # set input shape\n",
        "                             output_dim=128, # set size of embedding vector\n",
        "                             embeddings_initializer=\"uniform\", # default, intialize randomly\n",
        "                             input_length=avg_tokens) # how long is each input\n",
        "\n",
        "embedding(text_vectorizer(new_df['Sentence']))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(307, 25, 128), dtype=float32, numpy=\n",
              "array([[[ 5.0104149e-03,  3.5234224e-02, -2.8986169e-02, ...,\n",
              "         -2.8221322e-02, -2.2857077e-03, -2.5993362e-03],\n",
              "        [ 9.0782046e-03,  1.5913811e-02, -1.7580390e-03, ...,\n",
              "         -8.5942820e-04, -7.9221502e-03,  2.9427204e-02],\n",
              "        [-3.2362390e-02,  6.4261071e-03, -1.0967709e-02, ...,\n",
              "         -1.9243240e-02, -2.9514587e-02,  6.8360083e-03],\n",
              "        ...,\n",
              "        [ 2.5640760e-02, -3.2779947e-03, -1.1034392e-02, ...,\n",
              "          3.0237708e-02, -4.0322531e-02,  2.3042608e-02],\n",
              "        [ 5.0104149e-03,  3.5234224e-02, -2.8986169e-02, ...,\n",
              "         -2.8221322e-02, -2.2857077e-03, -2.5993362e-03],\n",
              "        [ 4.3088105e-02, -1.8636882e-02, -4.5479059e-02, ...,\n",
              "          3.7443828e-02,  2.6025858e-02, -4.8174299e-02]],\n",
              "\n",
              "       [[ 5.0104149e-03,  3.5234224e-02, -2.8986169e-02, ...,\n",
              "         -2.8221322e-02, -2.2857077e-03, -2.5993362e-03],\n",
              "        [-3.2996438e-02,  4.8160665e-03,  1.1765659e-02, ...,\n",
              "          1.8762436e-02, -3.5081394e-03,  2.6951943e-02],\n",
              "        [-2.6695967e-02, -4.7419693e-02, -1.5068427e-03, ...,\n",
              "          4.6781305e-02, -3.3624865e-02,  2.2437397e-02],\n",
              "        ...,\n",
              "        [ 3.7235189e-02, -4.2549014e-02,  1.6222063e-02, ...,\n",
              "         -3.7608970e-02,  8.9569204e-03, -4.8780706e-02],\n",
              "        [ 3.7235189e-02, -4.2549014e-02,  1.6222063e-02, ...,\n",
              "         -3.7608970e-02,  8.9569204e-03, -4.8780706e-02],\n",
              "        [ 3.7235189e-02, -4.2549014e-02,  1.6222063e-02, ...,\n",
              "         -3.7608970e-02,  8.9569204e-03, -4.8780706e-02]],\n",
              "\n",
              "       [[ 5.0104149e-03,  3.5234224e-02, -2.8986169e-02, ...,\n",
              "         -2.8221322e-02, -2.2857077e-03, -2.5993362e-03],\n",
              "        [-3.8636811e-03, -4.6774544e-02,  4.4020761e-02, ...,\n",
              "         -3.4921624e-02, -2.9354369e-02, -3.9857030e-03],\n",
              "        [-1.2120523e-02,  3.1068478e-02,  3.3964541e-02, ...,\n",
              "          1.0913290e-02,  3.6845420e-02, -2.2211766e-02],\n",
              "        ...,\n",
              "        [ 2.9844616e-02, -5.5762380e-04, -2.6156520e-02, ...,\n",
              "          4.7976878e-02,  2.6563779e-03,  3.4799743e-02],\n",
              "        [-4.3313313e-02, -1.4012586e-02, -4.5047868e-02, ...,\n",
              "          1.5230503e-02, -3.4962893e-02,  4.1765872e-02],\n",
              "        [ 4.4894192e-02,  2.3688558e-02, -3.3166148e-02, ...,\n",
              "          3.2166112e-02, -4.9688529e-02, -1.8372022e-02]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[-1.4795780e-02, -1.6605675e-02, -1.6770542e-02, ...,\n",
              "         -7.0952773e-03, -2.2820700e-02,  4.6196405e-02],\n",
              "        [ 5.0104149e-03,  3.5234224e-02, -2.8986169e-02, ...,\n",
              "         -2.8221322e-02, -2.2857077e-03, -2.5993362e-03],\n",
              "        [ 3.4772824e-02,  3.8037371e-02, -3.6450885e-02, ...,\n",
              "         -4.6397295e-02, -3.8168095e-02,  3.8248301e-03],\n",
              "        ...,\n",
              "        [ 3.6162522e-02, -1.1592269e-02,  2.3777176e-02, ...,\n",
              "         -2.8354753e-02, -2.2675550e-02, -4.2920362e-02],\n",
              "        [-9.5949657e-03,  3.2628290e-03, -4.9552526e-02, ...,\n",
              "          2.0159077e-02,  9.4503984e-03, -3.7500240e-02],\n",
              "        [ 5.0104149e-03,  3.5234224e-02, -2.8986169e-02, ...,\n",
              "         -2.8221322e-02, -2.2857077e-03, -2.5993362e-03]],\n",
              "\n",
              "       [[ 4.2524282e-02,  3.2294761e-02,  4.9630705e-02, ...,\n",
              "         -2.3797059e-02, -1.2618434e-02,  2.2427812e-03],\n",
              "        [ 3.7235189e-02, -4.2549014e-02,  1.6222063e-02, ...,\n",
              "         -3.7608970e-02,  8.9569204e-03, -4.8780706e-02],\n",
              "        [ 3.7235189e-02, -4.2549014e-02,  1.6222063e-02, ...,\n",
              "         -3.7608970e-02,  8.9569204e-03, -4.8780706e-02],\n",
              "        ...,\n",
              "        [ 3.7235189e-02, -4.2549014e-02,  1.6222063e-02, ...,\n",
              "         -3.7608970e-02,  8.9569204e-03, -4.8780706e-02],\n",
              "        [ 3.7235189e-02, -4.2549014e-02,  1.6222063e-02, ...,\n",
              "         -3.7608970e-02,  8.9569204e-03, -4.8780706e-02],\n",
              "        [ 3.7235189e-02, -4.2549014e-02,  1.6222063e-02, ...,\n",
              "         -3.7608970e-02,  8.9569204e-03, -4.8780706e-02]],\n",
              "\n",
              "       [[ 4.6072174e-02,  2.1819960e-02,  2.3542572e-02, ...,\n",
              "         -6.0795769e-03,  1.5724886e-02, -4.2498637e-02],\n",
              "        [-2.6141405e-02,  4.0508222e-02,  2.2938501e-02, ...,\n",
              "          3.0369688e-02,  4.4603501e-02, -3.4482062e-02],\n",
              "        [ 3.0034352e-02,  3.4191970e-02,  2.2339333e-02, ...,\n",
              "         -3.5848022e-03,  1.8518988e-02, -1.2310781e-02],\n",
              "        ...,\n",
              "        [ 1.2861256e-02, -2.8048253e-02, -2.2559011e-02, ...,\n",
              "         -4.4470169e-02, -3.6717452e-02, -2.9469622e-02],\n",
              "        [ 1.0801636e-02,  9.1797337e-03, -4.9762353e-03, ...,\n",
              "         -2.4938060e-02, -2.9974436e-02,  2.5509331e-02],\n",
              "        [-4.5317650e-02, -3.3722118e-02, -3.0826449e-02, ...,\n",
              "         -5.2295625e-05, -4.4189803e-03, -1.9360794e-02]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIu3Fp7fttP0"
      },
      "source": [
        "#import libraries for classification\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "def calculate_results(y_true, y_pred):\n",
        "  \"\"\"\n",
        "  Calculates model accuracy, precision, recall and f1 score of a binary classification model.\n",
        "\n",
        "  Args:\n",
        "  -----\n",
        "  y_true = true labels in the form of a 1D array\n",
        "  y_pred = predicted labels in the form of a 1D array\n",
        "\n",
        "  Returns a dictionary of accuracy, precision, recall, f1-score.\n",
        "  \"\"\"\n",
        "  # Calculate model accuracy\n",
        "  model_accuracy = accuracy_score(y_true, y_pred) * 100\n",
        "  # Calculate model precision, recall and f1 score using \"weighted\" average\n",
        "  model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
        "  model_results = {\"accuracy\": model_accuracy,\n",
        "                  \"precision\": model_precision,\n",
        "                  \"recall\": model_recall,\n",
        "                  \"f1\": model_f1}\n",
        "  return model_results\n"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RpW7qBXJJFGR"
      },
      "source": [
        "#lstm\n",
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "x = layers.LSTM(64)(x) # return vector for whole sequence\n",
        "x = layers.Dense(64, activation=\"relu\")(x) # optional dense layer on top of output of LSTM cell\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_lstm = tf.keras.Model(inputs, outputs, name=\"model_LSTM\")\n"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQaasE2SLnUL"
      },
      "source": [
        "model_lstm.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g6TLqhlbLtbz",
        "outputId": "cdb97783-f32c-4967-99ba-4f2d23d566ad"
      },
      "source": [
        "model_lstm.summary()"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_LSTM\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_14 (InputLayer)       [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization (TextVec  (None, 25)               0         \n",
            " torization)                                                     \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 25, 128)           1280000   \n",
            "                                                                 \n",
            " lstm_6 (LSTM)               (None, 64)                49408     \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,333,633\n",
            "Trainable params: 1,333,633\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AkmqLX8BLvO8",
        "outputId": "34237093-a6a4-4bc5-b728-4bd7406018c9"
      },
      "source": [
        "model_lstm_history = model_lstm.fit(train_split['Sentence'],\n",
        "                              train_split['Target'],\n",
        "                              epochs=9,\n",
        "                              validation_data=(test_split['Sentence'], test_split['Target']))\n"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/9\n",
            "8/8 [==============================] - 3s 103ms/step - loss: 0.6320 - accuracy: 0.8122 - val_loss: 0.5723 - val_accuracy: 0.9194\n",
            "Epoch 2/9\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.3534 - accuracy: 0.9918 - val_loss: 0.2048 - val_accuracy: 1.0000\n",
            "Epoch 3/9\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0498 - accuracy: 0.9918 - val_loss: 0.1564 - val_accuracy: 0.9516\n",
            "Epoch 4/9\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.2469 - val_accuracy: 0.9516\n",
            "Epoch 5/9\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2982 - val_accuracy: 0.9516\n",
            "Epoch 6/9\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 6.9889e-04 - accuracy: 1.0000 - val_loss: 0.4254 - val_accuracy: 0.9355\n",
            "Epoch 7/9\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 4.4585e-04 - accuracy: 1.0000 - val_loss: 0.4258 - val_accuracy: 0.9355\n",
            "Epoch 8/9\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 3.3937e-04 - accuracy: 1.0000 - val_loss: 0.4107 - val_accuracy: 0.9355\n",
            "Epoch 9/9\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 2.8306e-04 - accuracy: 1.0000 - val_loss: 0.4029 - val_accuracy: 0.9355\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O2qS5-pSMLqc",
        "outputId": "45f2ad3e-40df-47f6-e120-facb1f668a8b"
      },
      "source": [
        "model_lstm_pred_probs = model_lstm.predict(test_split['Sentence'])\n",
        "model_lstm_preds = tf.squeeze(tf.round(model_lstm_pred_probs))\n",
        "calculate_results(y_true=test_split['Target'], y_pred=model_lstm_preds)\n"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 93.54838709677419,\n",
              " 'f1': 0.9369825034655876,\n",
              " 'precision': 0.9467040673211782,\n",
              " 'recall': 0.9354838709677419}"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4lYimUjNkUZ"
      },
      "source": [
        "#GRU\n",
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "x = layers.GRU(64)(x) \n",
        "x = layers.Dense(64, activation=\"relu\")(x) # optional dense layer after GRU cell\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_gru = tf.keras.Model(inputs, outputs, name=\"model_GRU\")\n"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QQzEkvGNkWI"
      },
      "source": [
        "model_gru.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P63GbmYDNkYR",
        "outputId": "c8af3fad-90e9-4d6d-907c-4541b1b30f3a"
      },
      "source": [
        "model_gru_history = model_gru.fit(train_split['Sentence'],\n",
        "                              train_split['Target'],\n",
        "                              epochs=9,\n",
        "                              validation_data=(test_split['Sentence'], test_split['Target']))\n"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/9\n",
            "8/8 [==============================] - 3s 94ms/step - loss: 0.6579 - accuracy: 0.7592 - val_loss: 0.6200 - val_accuracy: 0.7742\n",
            "Epoch 2/9\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.5443 - accuracy: 0.8286 - val_loss: 0.5079 - val_accuracy: 0.8065\n",
            "Epoch 3/9\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.3527 - accuracy: 0.8653 - val_loss: 0.2651 - val_accuracy: 0.9032\n",
            "Epoch 4/9\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0795 - accuracy: 0.9796 - val_loss: 0.1471 - val_accuracy: 0.9355\n",
            "Epoch 5/9\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.3405 - val_accuracy: 0.9194\n",
            "Epoch 6/9\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 1.5222e-04 - accuracy: 1.0000 - val_loss: 0.3746 - val_accuracy: 0.9355\n",
            "Epoch 7/9\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 4.8482e-05 - accuracy: 1.0000 - val_loss: 0.3902 - val_accuracy: 0.9355\n",
            "Epoch 8/9\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 3.0418e-05 - accuracy: 1.0000 - val_loss: 0.3876 - val_accuracy: 0.9516\n",
            "Epoch 9/9\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 2.4401e-05 - accuracy: 1.0000 - val_loss: 0.3960 - val_accuracy: 0.9516\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ehia-s8tNkaV",
        "outputId": "9b4a9385-9110-4bdb-93be-c56d6758d61e"
      },
      "source": [
        "model_gru_pred_probs = model_gru.predict(test_split['Sentence'])\n",
        "model_gru_preds = tf.squeeze(tf.round(model_gru_pred_probs))\n",
        "calculate_results(y_true=test_split['Target'], y_pred=model_gru_preds)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 95.16129032258065,\n",
              " 'f1': 0.9525086972595338,\n",
              " 'precision': 0.9582111436950146,\n",
              " 'recall': 0.9516129032258065}"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8L6so5LeSHn5"
      },
      "source": [
        "#bidirectional LSTM\n",
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "# x = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(x) # stacking RNN layers requires return_sequences=True\n",
        "x = layers.Bidirectional(layers.LSTM(64))(x) # bidirectional goes both ways so has double the parameters of a regular LSTM layer\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_bi_lstm = tf.keras.Model(inputs, outputs, name=\"model_Bi_lstm\")\n"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZDUsyfeSOuo"
      },
      "source": [
        "model_bi_lstm.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5USTZa7zSQc3",
        "outputId": "4a32d988-c151-42f5-9848-ce4727125961"
      },
      "source": [
        "model_bi_lstm.summary()\n"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_Bi_lstm\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_11 (InputLayer)       [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization (TextVec  (None, 25)               0         \n",
            " torization)                                                     \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 25, 128)           1280000   \n",
            "                                                                 \n",
            " bidirectional_4 (Bidirectio  (None, 128)              98816     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,378,945\n",
            "Trainable params: 1,378,945\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfpOLQssSQ6k",
        "outputId": "d94ff59f-26fc-4c6b-904e-c5992ba82a63"
      },
      "source": [
        "model_bi_lstm_history = model_bi_lstm.fit(train_split['Sentence'],\n",
        "                              train_split['Target'],\n",
        "                              epochs=9,\n",
        "                              validation_data=(test_split['Sentence'], test_split['Target']))\n"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/9\n",
            "8/8 [==============================] - 5s 158ms/step - loss: 0.6020 - accuracy: 0.8122 - val_loss: 0.5113 - val_accuracy: 0.9516\n",
            "Epoch 2/9\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.2956 - accuracy: 1.0000 - val_loss: 0.2121 - val_accuracy: 0.9839\n",
            "Epoch 3/9\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.0625 - accuracy: 0.9959 - val_loss: 0.0680 - val_accuracy: 0.9839\n",
            "Epoch 4/9\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.0960 - val_accuracy: 0.9677\n",
            "Epoch 5/9\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.1154 - val_accuracy: 0.9677\n",
            "Epoch 6/9\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.1400 - val_accuracy: 0.9516\n",
            "Epoch 7/9\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1328 - val_accuracy: 0.9516\n",
            "Epoch 8/9\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.1002 - val_accuracy: 0.9516\n",
            "Epoch 9/9\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 8.2033e-04 - accuracy: 1.0000 - val_loss: 0.1384 - val_accuracy: 0.9677\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pAoIphfFFtzV",
        "outputId": "34bbf580-6d0e-43a2-ff08-8de1174eace1"
      },
      "source": [
        "model_bi_lstm_pred_probs = model_bi_lstm.predict(test_split['Sentence'])\n",
        "model_bi_lstm_preds = tf.squeeze(tf.round(model_bi_lstm_pred_probs))\n",
        "calculate_results(y_true=test_split['Target'], y_pred=model_bi_lstm_preds)"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 95.16129032258065,\n",
              " 'f1': 0.9525086972595338,\n",
              " 'precision': 0.9582111436950146,\n",
              " 'recall': 0.9516129032258065}"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IuxMkSKeTIBF"
      },
      "source": [
        "#bidirectional GRU\n",
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "x = layers.Bidirectional(layers.GRU(64))(x) # bidirectional goes both ways so has double the parameters of a regular LSTM layer\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_bi_gru = tf.keras.Model(inputs, outputs, name=\"model_Bi_gru\")"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wTDfkosTOQx"
      },
      "source": [
        "model_bi_gru.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xX0PT4rkTQZ4",
        "outputId": "fdee7631-c421-4364-83e2-15f00406549e"
      },
      "source": [
        "model_bi_gru.summary()"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_Bi_gru\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_13 (InputLayer)       [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization (TextVec  (None, 25)               0         \n",
            " torization)                                                     \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 25, 128)           1280000   \n",
            "                                                                 \n",
            " bidirectional_6 (Bidirectio  (None, 128)              74496     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,354,625\n",
            "Trainable params: 1,354,625\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AUA9dZgATS-R",
        "outputId": "c2b7a393-f367-40c7-d579-0a0b32de0fae"
      },
      "source": [
        "model_bi_gru_history = model_bi_gru.fit(train_split['Sentence'],\n",
        "                              train_split['Target'],\n",
        "                              epochs=9,\n",
        "                              validation_data=(test_split['Sentence'], test_split['Target']))"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/9\n",
            "8/8 [==============================] - 5s 154ms/step - loss: 0.5579 - accuracy: 0.9143 - val_loss: 0.4635 - val_accuracy: 0.8710\n",
            "Epoch 2/9\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 0.2975 - accuracy: 0.9837 - val_loss: 0.2767 - val_accuracy: 0.9516\n",
            "Epoch 3/9\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 0.0970 - accuracy: 1.0000 - val_loss: 0.1077 - val_accuracy: 0.9677\n",
            "Epoch 4/9\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 0.0689 - val_accuracy: 0.9677\n",
            "Epoch 5/9\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 6.0984e-04 - accuracy: 1.0000 - val_loss: 0.1114 - val_accuracy: 0.9677\n",
            "Epoch 6/9\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 2.9606e-04 - accuracy: 1.0000 - val_loss: 0.1338 - val_accuracy: 0.9677\n",
            "Epoch 7/9\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 2.5297e-04 - accuracy: 1.0000 - val_loss: 0.1429 - val_accuracy: 0.9677\n",
            "Epoch 8/9\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 1.9681e-04 - accuracy: 1.0000 - val_loss: 0.1421 - val_accuracy: 0.9677\n",
            "Epoch 9/9\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 1.3623e-04 - accuracy: 1.0000 - val_loss: 0.1405 - val_accuracy: 0.9677\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2UyLqg9Gl3n",
        "outputId": "cd9e5f29-334d-44ab-f1d0-edce3c4ab1b5"
      },
      "source": [
        "model_bi_gru_pred_probs = model_bi_gru.predict(test_split['Sentence'])\n",
        "model_bi_gru_preds = tf.squeeze(tf.round(model_bi_gru_pred_probs))\n",
        "calculate_results(y_true=test_split['Target'], y_pred=model_bi_gru_preds)"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 96.7741935483871,\n",
              " 'f1': 0.9681643625192012,\n",
              " 'precision': 0.9708141321044547,\n",
              " 'recall': 0.967741935483871}"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YjdJ4sLkHHLu"
      },
      "source": [
        "Every model has 9 epochs for learning. The best results were shown by bidirectional GRU model."
      ]
    }
  ]
}