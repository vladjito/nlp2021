{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lab5.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "3suJfqw4OdIB"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf, requests as rqst, io\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "rnd = np.random.randint"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5TWSacpQNqF-",
        "outputId": "c84bc787-ca6c-496e-a852-a81e1c7104f8"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1bwxXcKUAgf"
      },
      "source": [
        "#create the grouped dataset based on the data from each participant\n",
        "vlad_file = open(\"/content/drive/MyDrive/NLP/datavlad.txt\")\n",
        "vlad_sentences = vlad_file.read().split('.')[:-1]\n",
        "\n",
        "artem_file = open(\"/content/drive/MyDrive/NLP/dataartem.txt\")\n",
        "artem_sentences = artem_file.read().split('.')[:-1]\n",
        "\n",
        "ks_file = open(\"/content/drive/MyDrive/NLP/dataks.txt\")\n",
        "ks_sentences = ks_file.read().split('.')[:-1]"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "xXFtRDHpobtl",
        "outputId": "d3d3a3a4-b510-4aaa-9986-6de12a6ac8c7"
      },
      "source": [
        "new_df = []\n",
        "\n",
        "for new in vlad_sentences:\n",
        "  new_df.append({'Sentence':new, 'Label':'neural network art'})\n",
        "\n",
        "for new in ks_sentences:\n",
        "  new_df.append({'Sentence':new, 'Label':'climate change'})\n",
        "\n",
        "for new in artem_sentences:\n",
        "  new_df.append({'Sentence':new, 'Label':'neural network recognition'})\n",
        "\n",
        "new_df = pd.DataFrame(data=new_df, columns=['Sentence', 'Label'])\n",
        "\n",
        "new_df['Target'] = new_df['Label']\n",
        "new_df.replace({'Target':{'neural network art':1, 'climate change':0, 'neural network recognition':0}}, inplace=True)\n",
        "new_df"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Label</th>\n",
              "      <th>Target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>In the past few years, many artists have begun...</td>\n",
              "      <td>neural network art</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\\nIn computer vision and perceptual psychology...</td>\n",
              "      <td>neural network art</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\\nIn other words, modern neural models lend th...</td>\n",
              "      <td>neural network art</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\\nThe most prominent tool in neural art at the...</td>\n",
              "      <td>neural network art</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\\nGiven a large collection of images of a spec...</td>\n",
              "      <td>neural network art</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>302</th>\n",
              "      <td>\\nIn May 2017, a man was arrested using an aut...</td>\n",
              "      <td>neural network recognition</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>303</th>\n",
              "      <td>[68] Live facial recognition has been trialled...</td>\n",
              "      <td>neural network recognition</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>304</th>\n",
              "      <td>[69] In August 2020 the Court of Appeal ruled ...</td>\n",
              "      <td>neural network recognition</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>305</th>\n",
              "      <td>S</td>\n",
              "      <td>neural network recognition</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>306</th>\n",
              "      <td>Department of State operates one of the large...</td>\n",
              "      <td>neural network recognition</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>307 rows Ã— 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              Sentence  ... Target\n",
              "0    In the past few years, many artists have begun...  ...      1\n",
              "1    \\nIn computer vision and perceptual psychology...  ...      1\n",
              "2    \\nIn other words, modern neural models lend th...  ...      1\n",
              "3    \\nThe most prominent tool in neural art at the...  ...      1\n",
              "4    \\nGiven a large collection of images of a spec...  ...      1\n",
              "..                                                 ...  ...    ...\n",
              "302  \\nIn May 2017, a man was arrested using an aut...  ...      0\n",
              "303  [68] Live facial recognition has been trialled...  ...      0\n",
              "304  [69] In August 2020 the Court of Appeal ruled ...  ...      0\n",
              "305                                                  S  ...      0\n",
              "306   Department of State operates one of the large...  ...      0\n",
              "\n",
              "[307 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffu4h0ajN6IE"
      },
      "source": [
        "# vectorization of text\n",
        "max_tokens = 10000\n",
        "\n",
        "sentences = vlad_sentences+artem_sentences+ks_sentences\n",
        "tokens_count = 0\n",
        "for new in sentences:\n",
        "  tokens_count+=len(new.split())\n",
        "avg_tokens = round(tokens_count/len(sentences))"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fm1gjy-eUHB4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "288cd17c-d8b9-465c-c74c-d3690a0b5f54"
      },
      "source": [
        "#tokenization and embedding\n",
        "text_vectorizer = TextVectorization(max_tokens=max_tokens, \n",
        "                                    standardize=\"lower_and_strip_punctuation\", \n",
        "                                    split=\"whitespace\", \n",
        "                                    ngrams=None, \n",
        "                                    output_mode=\"int\",\n",
        "                                    output_sequence_length=avg_tokens, \n",
        "                                    pad_to_max_tokens=True)\n",
        "\n",
        "text_vectorizer.adapt(new_df['Sentence'])\n",
        "\n",
        "text_vectorizer(new_df['Sentence'])"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(307, 25), dtype=int64, numpy=\n",
              "array([[   6,    2,  212, ...,  826,    6, 1800],\n",
              "       [   6,  303,  328, ...,    0,    0,    0],\n",
              "       [   6,   62,  325, ...,  139,  455,  266],\n",
              "       ...,\n",
              "       [2051,    6, 1943, ...,  251,  101,    6],\n",
              "       [ 575,    0,    0, ...,    0,    0,    0],\n",
              "       [ 763,    3,  363, ...,   24,  102,  524]])>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HsUT7y2avSdJ",
        "outputId": "87d8131e-3430-45fa-cd52-c4f9da21e6f1"
      },
      "source": [
        "embedding = layers.Embedding(input_dim=max_tokens, # set input shape\n",
        "                             output_dim=128, # set size of embedding vector\n",
        "                             embeddings_initializer=\"uniform\", # default, intialize randomly\n",
        "                             input_length=avg_tokens) # how long is each input\n",
        "\n",
        "embedding(text_vectorizer(new_df['Sentence']))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(307, 25, 128), dtype=float32, numpy=\n",
              "array([[[-0.0233851 , -0.01348491, -0.03136371, ..., -0.03432669,\n",
              "         -0.01660462, -0.01027635],\n",
              "        [-0.01769461,  0.03343001, -0.00187425, ..., -0.04508854,\n",
              "         -0.04897651, -0.04471302],\n",
              "        [ 0.03980151,  0.03117919, -0.00617325, ...,  0.02765748,\n",
              "          0.03162095, -0.03758148],\n",
              "        ...,\n",
              "        [ 0.04871792,  0.04337497,  0.02303931, ..., -0.04296513,\n",
              "          0.03719758,  0.04070419],\n",
              "        [-0.0233851 , -0.01348491, -0.03136371, ..., -0.03432669,\n",
              "         -0.01660462, -0.01027635],\n",
              "        [ 0.02497759, -0.02604815, -0.03634252, ..., -0.01039992,\n",
              "          0.01683113, -0.02052484]],\n",
              "\n",
              "       [[-0.0233851 , -0.01348491, -0.03136371, ..., -0.03432669,\n",
              "         -0.01660462, -0.01027635],\n",
              "        [-0.02103479, -0.03589001, -0.00330781, ..., -0.02518375,\n",
              "         -0.03208981, -0.02051231],\n",
              "        [ 0.02694023,  0.02850043, -0.00638145, ...,  0.02723211,\n",
              "          0.03869936,  0.01958818],\n",
              "        ...,\n",
              "        [ 0.04721657, -0.02934825, -0.0370589 , ...,  0.04183808,\n",
              "          0.01912614,  0.04914478],\n",
              "        [ 0.04721657, -0.02934825, -0.0370589 , ...,  0.04183808,\n",
              "          0.01912614,  0.04914478],\n",
              "        [ 0.04721657, -0.02934825, -0.0370589 , ...,  0.04183808,\n",
              "          0.01912614,  0.04914478]],\n",
              "\n",
              "       [[-0.0233851 , -0.01348491, -0.03136371, ..., -0.03432669,\n",
              "         -0.01660462, -0.01027635],\n",
              "        [-0.03843666, -0.04258759, -0.01197324, ...,  0.01748251,\n",
              "         -0.04995951,  0.00208411],\n",
              "        [-0.03048443, -0.03777283, -0.04492093, ...,  0.04617322,\n",
              "          0.04091735, -0.02777561],\n",
              "        ...,\n",
              "        [ 0.02727253, -0.03099005, -0.01162832, ...,  0.0189974 ,\n",
              "          0.0371791 , -0.00829317],\n",
              "        [ 0.00343289, -0.04276776, -0.0345556 , ..., -0.00082435,\n",
              "          0.04313565, -0.0473836 ],\n",
              "        [ 0.0206222 , -0.00079708,  0.03810308, ...,  0.03906183,\n",
              "          0.02369762,  0.01403597]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[-0.00426199,  0.01172094,  0.01420743, ...,  0.048226  ,\n",
              "         -0.01858459, -0.02440525],\n",
              "        [-0.0233851 , -0.01348491, -0.03136371, ..., -0.03432669,\n",
              "         -0.01660462, -0.01027635],\n",
              "        [-0.02494229, -0.01177552, -0.03143086, ...,  0.02133752,\n",
              "          0.03686636, -0.01521545],\n",
              "        ...,\n",
              "        [-0.04634289, -0.04347118, -0.00112195, ..., -0.02990562,\n",
              "          0.01191799,  0.023481  ],\n",
              "        [ 0.02639401, -0.02202069, -0.04922594, ...,  0.01964028,\n",
              "          0.03810051, -0.00122394],\n",
              "        [-0.0233851 , -0.01348491, -0.03136371, ..., -0.03432669,\n",
              "         -0.01660462, -0.01027635]],\n",
              "\n",
              "       [[-0.02851851, -0.02758906, -0.00489498, ..., -0.03718116,\n",
              "         -0.00326903,  0.04760108],\n",
              "        [ 0.04721657, -0.02934825, -0.0370589 , ...,  0.04183808,\n",
              "          0.01912614,  0.04914478],\n",
              "        [ 0.04721657, -0.02934825, -0.0370589 , ...,  0.04183808,\n",
              "          0.01912614,  0.04914478],\n",
              "        ...,\n",
              "        [ 0.04721657, -0.02934825, -0.0370589 , ...,  0.04183808,\n",
              "          0.01912614,  0.04914478],\n",
              "        [ 0.04721657, -0.02934825, -0.0370589 , ...,  0.04183808,\n",
              "          0.01912614,  0.04914478],\n",
              "        [ 0.04721657, -0.02934825, -0.0370589 , ...,  0.04183808,\n",
              "          0.01912614,  0.04914478]],\n",
              "\n",
              "       [[-0.00542383,  0.00225167,  0.00621998, ...,  0.00965997,\n",
              "         -0.0389599 ,  0.01382809],\n",
              "        [-0.03125357,  0.00948411, -0.02193127, ...,  0.00414326,\n",
              "         -0.02436941,  0.04011171],\n",
              "        [-0.00107998, -0.01305466,  0.00930599, ...,  0.04938892,\n",
              "         -0.0421279 , -0.009073  ],\n",
              "        ...,\n",
              "        [-0.00647732, -0.02090172,  0.02738067, ...,  0.04544672,\n",
              "          0.02651714,  0.03887985],\n",
              "        [-0.01018071, -0.03610171, -0.03501208, ..., -0.04602946,\n",
              "         -0.045775  , -0.04079596],\n",
              "        [-0.01279119, -0.01525269,  0.00375127, ...,  0.02001566,\n",
              "          0.01719273,  0.0368267 ]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7L-Q1oaDVZLw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "37b79a48-448c-4575-ffcf-34b5f84968f2"
      },
      "source": [
        "# import libraries\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_split, test_split = train_test_split(new_df, train_size=0.8, test_size=0.2)\n",
        "train_split"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Label</th>\n",
              "      <th>Target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>223</th>\n",
              "      <td>Scientists have attributed the fires, which i...</td>\n",
              "      <td>climate change</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>224</th>\n",
              "      <td>California governor Jerry Brown lamented that...</td>\n",
              "      <td>climate change</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>186</th>\n",
              "      <td>\\nHumans have created and released greenhouse ...</td>\n",
              "      <td>climate change</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>\\nHowever, GANs operate in terms of image cues...</td>\n",
              "      <td>neural network art</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>262</th>\n",
              "      <td>\\nAmid this ongoing uncertainty, we believe th...</td>\n",
              "      <td>neural network recognition</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>304</th>\n",
              "      <td>[69] In August 2020 the Court of Appeal ruled ...</td>\n",
              "      <td>neural network recognition</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>\\nWhen synthesising an image that combines the...</td>\n",
              "      <td>neural network art</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>233</th>\n",
              "      <td>Plants and animals might not be able to survi...</td>\n",
              "      <td>climate change</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>297</th>\n",
              "      <td>\\nThree-dimensional data points from a face va...</td>\n",
              "      <td>neural network recognition</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>237</th>\n",
              "      <td>\\nPattern recognition systems can recognize fa...</td>\n",
              "      <td>neural network recognition</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>245 rows Ã— 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              Sentence  ... Target\n",
              "223   Scientists have attributed the fires, which i...  ...      0\n",
              "224   California governor Jerry Brown lamented that...  ...      0\n",
              "186  \\nHumans have created and released greenhouse ...  ...      0\n",
              "5    \\nHowever, GANs operate in terms of image cues...  ...      1\n",
              "262  \\nAmid this ongoing uncertainty, we believe th...  ...      0\n",
              "..                                                 ...  ...    ...\n",
              "304  [69] In August 2020 the Court of Appeal ruled ...  ...      0\n",
              "49   \\nWhen synthesising an image that combines the...  ...      1\n",
              "233   Plants and animals might not be able to survi...  ...      0\n",
              "297  \\nThree-dimensional data points from a face va...  ...      0\n",
              "237  \\nPattern recognition systems can recognize fa...  ...      0\n",
              "\n",
              "[245 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIu3Fp7fttP0"
      },
      "source": [
        "#import libraries for classification\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "def calculate_results(y_true, y_pred):\n",
        "  \"\"\"\n",
        "  Calculates model accuracy, precision, recall and f1 score of a binary classification model.\n",
        "\n",
        "  Args:\n",
        "  -----\n",
        "  y_true = true labels in the form of a 1D array\n",
        "  y_pred = predicted labels in the form of a 1D array\n",
        "\n",
        "  Returns a dictionary of accuracy, precision, recall, f1-score.\n",
        "  \"\"\"\n",
        "  # Calculate model accuracy\n",
        "  model_accuracy = accuracy_score(y_true, y_pred) * 100\n",
        "  # Calculate model precision, recall and f1 score using \"weighted\" average\n",
        "  model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
        "  model_results = {\"accuracy\": model_accuracy,\n",
        "                  \"precision\": model_precision,\n",
        "                  \"recall\": model_recall,\n",
        "                  \"f1\": model_f1}\n",
        "  return model_results\n",
        "\n"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LNJQMuQDhJ9E",
        "outputId": "6ef07443-e70d-4163-a2f8-0c5b5d1ba5e6"
      },
      "source": [
        "#universal sentence encoder (USE)\n",
        "import tensorflow_hub as hub\n",
        "url=\"https://tfhub.dev/google/universal-sentence-encoder/4\"\n",
        "\n",
        "sentence_encoder_layer = hub.KerasLayer(url,input_shape=[], # shape of inputs coming to our model \n",
        "                                        dtype=tf.string, # data type of inputs coming to the USE layer\n",
        "                                        trainable=False, # keep the pretrained weights (we'll create a feature extractor)\n",
        "                                        name=\"USE\")\n",
        "\n",
        "model_use = tf.keras.Sequential([\n",
        "  sentence_encoder_layer, # take in sentences and then encode them into an embedding\n",
        "  layers.Dense(64, activation=\"relu\"),\n",
        "  layers.Dense(1, activation=\"sigmoid\")\n",
        "], name=\"model_6_USE\")\n",
        "\n",
        "# Compile model\n",
        "model_use.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "model_use.summary()\n"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_6_USE\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " USE (KerasLayer)            (None, 512)               256797824 \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 64)                32832     \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 256,830,721\n",
            "Trainable params: 32,897\n",
            "Non-trainable params: 256,797,824\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WtKcJCZAhKBi",
        "outputId": "b7b864d9-4b7b-4436-c365-1f17597c30f8"
      },
      "source": [
        "model_use_history=model_use.fit(train_split['Sentence'],train_split['Target'],epochs=9,\n",
        "                        validation_data=(test_split['Sentence'],test_split['Target']))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/9\n",
            "8/8 [==============================] - 3s 95ms/step - loss: 0.6675 - accuracy: 0.7224 - val_loss: 0.6164 - val_accuracy: 0.9516\n",
            "Epoch 2/9\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.5846 - accuracy: 0.9673 - val_loss: 0.5368 - val_accuracy: 0.9516\n",
            "Epoch 3/9\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.5004 - accuracy: 0.9673 - val_loss: 0.4524 - val_accuracy: 0.9677\n",
            "Epoch 4/9\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.4149 - accuracy: 0.9714 - val_loss: 0.3747 - val_accuracy: 0.9516\n",
            "Epoch 5/9\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.3378 - accuracy: 0.9796 - val_loss: 0.3075 - val_accuracy: 0.9516\n",
            "Epoch 6/9\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.2719 - accuracy: 0.9714 - val_loss: 0.2552 - val_accuracy: 0.9516\n",
            "Epoch 7/9\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.2210 - accuracy: 0.9714 - val_loss: 0.2139 - val_accuracy: 0.9677\n",
            "Epoch 8/9\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.1804 - accuracy: 0.9796 - val_loss: 0.1832 - val_accuracy: 0.9677\n",
            "Epoch 9/9\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.1504 - accuracy: 0.9878 - val_loss: 0.1597 - val_accuracy: 0.9677\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4h0f9siqaqTb",
        "outputId": "299a4080-d739-4f06-af49-839aed8f13fc"
      },
      "source": [
        "model_use_pred_probs = model_use.predict(test_split['Sentence'])\n",
        "model_use_preds = tf.squeeze(tf.round(model_use_pred_probs))\n",
        "calculate_results(y_true=test_split['Target'], y_pred=model_use_preds)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f88030da170> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f88030da170> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 96.7741935483871,\n",
              " 'f1': 0.967741935483871,\n",
              " 'precision': 0.967741935483871,\n",
              " 'recall': 0.967741935483871}"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mHCEdJDLh3xD",
        "outputId": "a419b56a-992c-419a-9787-12a4bb0b53c9"
      },
      "source": [
        "#universal sentence encoder (USE) with fine tuning\n",
        "tf_hub_embedding_layer = hub.KerasLayer(url,input_shape=[], # shape of inputs coming to our model \n",
        "                                        dtype=tf.string, # data type of inputs coming to the USE layer\n",
        "                                        trainable=True, \n",
        "                                        name=\"USE-FT\")\n",
        "\n",
        "model_use_ft = tf.keras.Sequential([\n",
        "  tf_hub_embedding_layer, # take in sentences and then encode them into an embedding\n",
        "  layers.Dense(64, activation=\"relu\"),\n",
        "  layers.Dense(1, activation=\"sigmoid\")\n",
        "], name=\"model_use_ft\")\n",
        "\n",
        "# Compile model\n",
        "model_use_ft.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "model_use_ft.summary()\n"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_use_ft\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " USE-FT (KerasLayer)         (None, 512)               256797824 \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 64)                32832     \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 256,830,721\n",
            "Trainable params: 256,830,721\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RsavUcSNjGgL",
        "outputId": "ec44ddd0-72b4-426f-ca6f-1d618aa11a54"
      },
      "source": [
        "model_use_ft_history=model_use_ft.fit(train_split['Sentence'],train_split['Target'],epochs=9,\n",
        "                        validation_data=(test_split['Sentence'],test_split['Target']))\n"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/9\n",
            "8/8 [==============================] - 10s 318ms/step - loss: 0.5920 - accuracy: 0.6653 - val_loss: 0.4956 - val_accuracy: 0.6774\n",
            "Epoch 2/9\n",
            "8/8 [==============================] - 2s 242ms/step - loss: 0.3963 - accuracy: 0.9061 - val_loss: 0.3279 - val_accuracy: 0.9355\n",
            "Epoch 3/9\n",
            "8/8 [==============================] - 2s 249ms/step - loss: 0.2400 - accuracy: 0.9755 - val_loss: 0.2113 - val_accuracy: 0.9516\n",
            "Epoch 4/9\n",
            "8/8 [==============================] - 2s 245ms/step - loss: 0.1344 - accuracy: 0.9918 - val_loss: 0.1438 - val_accuracy: 0.9677\n",
            "Epoch 5/9\n",
            "8/8 [==============================] - 2s 241ms/step - loss: 0.0658 - accuracy: 1.0000 - val_loss: 0.0710 - val_accuracy: 0.9839\n",
            "Epoch 6/9\n",
            "8/8 [==============================] - 2s 242ms/step - loss: 0.0345 - accuracy: 1.0000 - val_loss: 0.0486 - val_accuracy: 0.9839\n",
            "Epoch 7/9\n",
            "8/8 [==============================] - 2s 242ms/step - loss: 0.0190 - accuracy: 1.0000 - val_loss: 0.0368 - val_accuracy: 1.0000\n",
            "Epoch 8/9\n",
            "8/8 [==============================] - 2s 244ms/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 0.0311 - val_accuracy: 1.0000\n",
            "Epoch 9/9\n",
            "8/8 [==============================] - 2s 242ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.0258 - val_accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AgyCZgD2g3bg",
        "outputId": "44d40e5f-5342-4d6d-b906-9bda1134fe7a"
      },
      "source": [
        "model_use_ft_pred_probs = model_use_ft.predict(test_split['Sentence'])\n",
        "model_use_ft_preds = tf.squeeze(tf.round(model_use_ft_pred_probs))\n",
        "calculate_results(y_true=test_split['Target'], y_pred=model_use_ft_preds)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 100.0, 'f1': 1.0, 'precision': 1.0, 'recall': 1.0}"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XWbnSxtfp8T2"
      },
      "source": [
        "Universal sentence encoder (USE) with fine tuning showed better results - it reached the accuracy of 100%\n"
      ]
    }
  ]
}