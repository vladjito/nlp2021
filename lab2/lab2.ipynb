{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifAPvdFTA_Km"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf, requests as rqst, io\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "rnd = np.random.randint"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zQDp-0XJG8z",
        "outputId": "063e7bb9-8f2f-45a1-8250-533223866bd7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwIabRAeYeVC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "432ba7f0-795c-47cc-979f-8a4518bbba91"
      },
      "source": [
        "file = open(\"/content/drive/MyDrive/NLP/datavlad.txt\")\n",
        "sentences = file.read().split('.')[:-1]\n",
        "sentences"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['In the past few years, many artists have begun to explore neural networks as artistic tools, and their works have begun to appear in cutting-edge “Artificial Intelligence” art shows as well',\n",
              " '\\nIn computer vision and perceptual psychology, image perception is often analyzed in terms of visual cues',\n",
              " '\\nIn other words, modern neural models lend themselves to creating interesting imagery, because they were designed modern real images, and so modifying them creates realistic but unreal images',\n",
              " '\\nThe most prominent tool in neural art at the moment is the Generative Adversarial Network (GAN)',\n",
              " '\\nGiven a large collection of images of a specific class (such as faces or landscapes), a GAN is trained to produce new images that look like they also came from that class',\n",
              " '\\nHowever, GANs operate in terms of image cues that are difficult to explain; they are not just manipulating simple properties like color and texture',\n",
              " '\\nGANs are the latest in a long line of research in natural image modeling',\n",
              " '\\nVision neuroscience has long sought to build statistical models of “natural images,” originally referring to images in prehistorical environments, but now referring to any realistic photos of the world',\n",
              " '\\nThe Generator is optimized according to the Discriminator, which is a classification network meant to recognize whether images are “real”',\n",
              " '\\nIn other words, GAN generator nets have learned how to plausibly compose objects together in scenes and to texture the object parts, following the instructions encoded in the vector z',\n",
              " '\\nThis method was trained on ImageNet, an enormous and diverse collection of real-world images; based on the training details in the paper, it has been estimated that model training used an amount of power consumption equivalent to a typical US household’s usage over 6 months',\n",
              " '\\nMuch of the work that artists do with GANs is to explore the latent space and experiment with different ways to generate z vectors',\n",
              " '\\nWe now apply the theory to image stylization algorithms',\n",
              " '\\nThese algorithms take a natural image as input and output a stylized version, such as a painting',\n",
              " '\\nThey often express this task as an optimization that trades-off two goals: producing an image that has the overall appearance and structure of the given photograph, while also constructing the image from style elements, such as paint strokes or tiles',\n",
              " '\\nThat is, the image appears to be a real scene but also appears to be composed of unrelated texture',\n",
              " '\\nNeural image translation methods, like pix2pix and CycleGAN, learn to transform images, given before-and-after pairs as training',\n",
              " '\\nRather than attemping to model natural images, they model image transformations',\n",
              " '\\nIn this case, the GAN creates a new visual style for input imagery, rather than creating new imagery from scratch',\n",
              " '\\nAnother class of works also arose from attempts to visualize neural network classifiers',\n",
              " '\\nTom White’s “Perception Engines” series combines classifier visualization with stroke-based optimization, while producing an intriguing new take on abstract art',\n",
              " '\\nThese images are optimized according to natural image classifiers that are trained to distinguish photographs from one another, for example, looking for cues that distinguish photos of, say, violins from any other object class',\n",
              " '\\nIn each of these cases, there is a tension between the apparent abstraction of the image strokes and the object class cues specified by the classifier',\n",
              " '\\nGiven ongoing battles in our society over which kinds of images are offensive and why, they provide an interesting example of how something can seem somehow “obscene” while being purely abstract',\n",
              " '\\nAs described above, realistic drawings get some of their appeal from depicting natural scenes with specific style elements',\n",
              " '\\nThis suggests the following interpretation of Pollock’s paintings: they are interesting because they juxtapose some overall cues of natural scenes with fine details that are completely non-naturalistic',\n",
              " '\\nHis entirely-abstract Ocean Park series explicitly references landscapes in the title, the colors, and the layout of abstract shapes',\n",
              " '\\nIn this way, Tom White’s abstract stroke arrangements can be thought of as an implementation of an explicit model of some abstract expressionism: creating abstract arrangements with some of the statistics of natural images',\n",
              " '\\nThis paper presents a sort of recipe for making interesting images: begin with the latest research in natural image modeling, and then modify some elements of the model while preserving others',\n",
              " '\\nAs new models are developed, trained, and released in the coming years, we can expect that artists will continue to seize on these models and exploit them to create new and fascinating imagery',\n",
              " '\\nEven if new GANs become flawless, artists will still tweak them to produce surprising new imagery',\n",
              " '\\nIn fine art, especially painting, humans have mastered the skill to create unique visual experiences through composing a complex interplay between the content and style of an image',\n",
              " '\\nThus far the algorithmic basis of this process is unknown and there exists no artificial system with similar capabilities',\n",
              " '\\nHere we introduce an artificial system based on a Deep Neural Network that creates artistic images of high perceptual quality',\n",
              " '\\nThe system uses neural representations to separate and recombine content and style of arbitrary images, providing a neural algorithm for the creation of artistic images',\n",
              " '\\nThe class of Deep Neural Networks that are most powerful in image processing tasks are called Convolutional Neural Networks',\n",
              " '\\nEach layer of units can be understood as a collection of image filters, each of which extracts a certain feature from the input image',\n",
              " '\\nWhen Convolutional Neural Networks are trained on object recognition, they develop a representation of the image that makes object information increasingly explicit along the processing hierarchy',\n",
              " '\\nWe can directly visualise the information each layer contains about the input image by reconstructing the image only from the feature maps in that layer (Fig 1, content reconstructions, see Methods for details on how to reconstruct the image)',\n",
              " '\\nTo obtain a representation of the style of an input image, we use a feature space originally designed to capture texture information',\n",
              " '\\nWhile the number of different filters increases along the processing hierarchy, the size of the filtered images is reduced by some downsampling mechanism (e',\n",
              " 'g',\n",
              " ' max-pooling) leading to a decrease in the total number of units per layer of the network',\n",
              " '\\nA given input image is represented as a set of filtered images at each processing stage in the CNN',\n",
              " '\\nOn top of the original CNN representations we built a new feature space that captures the style of an input image',\n",
              " '\\nMoreover, the size and complexity of local image structures from the input image increases along the hierarchy, a result that can be explained by the increasing receptive field sizes and feature complexity',\n",
              " '\\nThat is, we can manipulate both representations independently to produce new, perceptually meaningful images',\n",
              " '\\nWhen matching the style representations up to higher layers in the network, local images structures are matched on an increasingly large scale, leading to a smoother and more continuous visual experience',\n",
              " '\\nThus, the visually most appealing images are usually created by matching the style representation up to the highest layers in the network',\n",
              " '\\nWhen synthesising an image that combines the content of one image with the style of another, there usually does not exist an image that perfectly matches both constraints at the same time',\n",
              " '\\nA strong emphasis on style will result in images that match the appearance of the artwork, effectively giving a texturised version of it, but hardly show any of the photograph’s content',\n",
              " '\\nHere we present an artificial neural system that achieves a separation of image content from style, thus allowing to recast the content of one image in the style of any other image',\n",
              " '\\nIn particular, we derive the neural representations for the content and style of an image from the feature responses of highperforming Deep Neural Networks trained on object recognition',\n",
              " '\\nConceptually most closely related are methods using texture transfer to achieve artistic style transfer',\n",
              " '\\nIn contrast, by using Deep Neural Networks trained on object recognition, we carry out manipulations in feature spaces that explicitly represent the high level content of an image',\n",
              " '\\nFeatures from Deep Neural Networks trained on object recognition have been previously used for style recognition in order to classify artworks according to the period in which they were created',\n",
              " '\\nWe conjecture that a transformation into a stationary feature space such as our style representation might achieve even better performance in style classification',\n",
              " '\\nAll in all it is truly fascinating that a neural system, which is trained to perform one of the core computational tasks of biological vision, automatically learns image representations that allow the separation of image content from style',\n",
              " '\\nThus, our ability to abstract content from style and therefore our ability to create and enjoy art might be primarily a preeminent signature of the powerful inference capabilities of our visual system',\n",
              " '\\nIn texture transfer the goal is to synthesise a texture from a source image while constraining the texture synthesis in order to preserve the semantic content of a target image',\n",
              " '\\nMost previous texture transfer algorithms rely on these nonparametric methods for texture synthesis while using different ways to preserve the structure of the target image',\n",
              " '\\nAlthough these algorithms achieve remarkable results, they all suffer from the same fundamental limitation: they use only low-level image features of the target image to inform the texture transfer',\n",
              " '\\nHere we demonstrate how to use feature representations from high-performing Convolutional Neural Networks to transfer image style between arbitrary images',\n",
              " '\\nWhile this is less of an issue in the artistic style transfer, the problem becomes more apparent when both, content and style images, are photographs and the photorealism of the synthesised image is affected',\n",
              " '\\nArtistic stylisation of images is traditionally studied in computer graphics under the label of non-photorealistic rendering',\n",
              " '\\nThis paper presents a multi-stage machine learning approach to the problem of semantic categorization of images depicting fine art paintings',\n",
              " '\\nThe ability to recognize an artistic style in fine art paintings is an attribute of highly educated and experienced art scholars who spend years analyzing and learning the specifics and nuances of the fine art objects',\n",
              " '\\nDue to the rapidly expanding availability of the online galleries, as well as various other sources of fine art pictures, fine art has become accessible to the masses, which in turn created a need to make the art expertise more easily available to the public',\n",
              " '\\nMachine-based art expertise can be used in automatic image retrieval, in art classes and in labeling of unsigned paintings at auction houses',\n",
              " '\\nIn visual arts, style is defined as a set of distinctive elements that can be associated with a specific artistic movement, school or time period',\n",
              " '\\nTransfer learning allows the adaptation or reuse of a network model that has been trained for a specific task using a very large dataset to perform a new, related task for which only a small dataset is available',\n",
              " '\\nOne of the possible reasons is that standard CNN architectures, used in most studies, require a fixed input image size that is in most cases, significantly smaller than the high-resolution art images offered by fine art datasets',\n",
              " '\\nTo address this problem, a sub-region approach was introduced in which the original image is divided into smaller regions (or image patches), where the size of each patch matches the standard image input size required by the CNN model',\n",
              " '\\nFirst, the proposed approach divides the input image into patches and applies a deep neural network to train and classify each patch',\n",
              " '\\nThe fine art classification task has been addressed through a wide range of methods',\n",
              " '\\nTwenty-five styles represented by a large dataset of digitized paintings were categorized using features generated by a pre-trained CNN model',\n",
              " '\\nFurther improvement of style classification was achieved through the application of transfer learning with the CNN model used to do both, feature learning and label inference',\n",
              " '\\nThe findings revealed a strong correlation between the CNN features and the chronology of paintings',\n",
              " '\\nThe study implemented the SVM model trained on features extracted from the CNN model to perform a binary identification of Vincent van Gogh’s paintings',\n",
              " '\\nArtist recognition based images of paper prints of artworks were performed using the average score obtained by independent CNNs trained on different image scales',\n",
              " '\\nA complex three-branch CNN structure was trained using a dataset of 2338 images with 13 categories to classify paintings by style',\n",
              " '\\nWhile the first stage deep CNN classifier is trained on images, the second stage shallow NN is trained on the class-probability vectors resulting from the first stage classification',\n",
              " '\\nThree datasets of digital images of paintings collated from publicly available fine art collections, with the addition of an Australian Aboriginal art dataset created by the authors, were used to empirically validate the efficacy of the proposed method',\n",
              " '\\nThe stylistic classes were balanced, and each class was represented by 5145 images (16',\n",
              " '66% of the total number of pictures)',\n",
              " '\\nIt confirms the benefits of having a second-stage classifier trained not on the images but on the class-probability vectors',\n",
              " '\\nIt can be noticed that the higher the CNN complexity, the better the classification outcomes disregarding the method and the database',\n",
              " '\\nA new machine learning method for automatic fine art style classification was presented and evaluated',\n",
              " '\\nIn this paper we will talk about the development of computer programs capable of creating artworks',\n",
              " '\\nThe vast majority of AI applications in the field of the arts falls into two categories: Systems performing some sort of art understanding task, such as musical analysis, and systems that work as “intelligent” tools for human artists (Spector & Alpern 1994); and a new range of applications that is beginning to emerge, the constructed artists which “are supposed to be capable of creating aesthetically meritorious artworks on their own, with minimal human intervention',\n",
              " '\\nIn the development of a model for a “constructed artist”, we took into consideration the previously referred characteristics that a constructed artist should have',\n",
              " '\\nFor the generation of the images, we rely on a Genetic Algorithm',\n",
              " '\\nThis type of approach relies on the assumption that the combination of two highly fit images results, at least generally, in a fit image',\n",
              " '\\nIn the proposed system, a convolutional neural network is learned so that images can be classified into a group based on a touch, with saturation and value and the histogram of saturation and value as input data, and the trained network is used to realize the retrieval',\n",
              " '\\xa0\\nThen, the image and the normalized feature vector corresponding to the image are associated and stored in the database',\n",
              " '\\nIn this paper, we explore the secret nature of human painting and propose an automatic image-to-painting translation method that generates vivid and realistic paintings with controllable styles',\n",
              " '\\nOur method can “draw” in a variety of painting styles, e',\n",
              " 'g',\n",
              " ' oil-painting brush, watercolor ink, marker-pen, and tape art',\n",
              " '\\nWe test our method on various real-world images and photos, including human portraits, animals, scenery, daily objects, art photography, and cartoon images',\n",
              " '\\nWe propose a new method for stroke based image-topainting translation',\n",
              " '\\nTo build a neural renderer, a general practice is to build a deep convolutional network and train it to imitate the behavior of a graphic engine',\n",
              " '\\nWe can see that our method successfully learns high-level abstractions of the characters and vividly portrays their shape and color',\n",
              " '\\nWe can see our method generates more vivid results with a clear distinction on brush textures, while the method “Learning-to-Paint” tends to produce blurred results',\n",
              " '\\nWe consider this artistic creation process under a stroke parameter searching paradigm that maximizes the similarity between the sequentially rendered canvas and the refe']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwYKBe1Ah1Ol",
        "outputId": "8517a86d-da8c-44b6-b0e9-5f8ffe330a85"
      },
      "source": [
        "new_df = []\n",
        "for sent in sentences:\n",
        "  new_df.append({'Sentence':sent, 'Label':\"Neural network artworks\"})\n",
        "\n",
        "new_df"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'Label': 'Neural network artworks',\n",
              "  'Sentence': 'In the past few years, many artists have begun to explore neural networks as artistic tools, and their works have begun to appear in cutting-edge “Artificial Intelligence” art shows as well'},\n",
              " {'Label': 'Neural network artworks',\n",
              "  'Sentence': '\\nIn computer vision and perceptual psychology, image perception is often analyzed in terms of visual cues'},\n",
              " {'Label': 'Neural network artworks',\n",
              "  'Sentence': '\\nIn other words, modern neural models lend themselves to creating interesting imagery, because they were designed modern real images, and so modifying them creates realistic but unreal images'},\n",
              " {'Label': 'Neural network artworks',\n",
              "  'Sentence': '\\nThe most prominent tool in neural art at the moment is the Generative Adversarial Network (GAN)'},\n",
              " {'Label': 'Neural network artworks',\n",
              "  'Sentence': '\\nGiven a large collection of images of a specific class (such as faces or landscapes), a GAN is trained to produce new images that look like they also came from that class'},\n",
              " {'Label': 'Neural network artworks',\n",
              "  'Sentence': '\\nHowever, GANs operate in terms of image cues that are difficult to explain; they are not just manipulating simple properties like color and texture'},\n",
              " {'Label': 'Neural network artworks',\n",
              "  'Sentence': '\\nGANs are the latest in a long line of research in natural image modeling'},\n",
              " {'Label': 'Neural network artworks',\n",
              "  'Sentence': '\\nVision neuroscience has long sought to build statistical models of “natural images,” originally referring to images in prehistorical environments, but now referring to any realistic photos of the world'},\n",
              " {'Label': 'Neural network artworks',\n",
              "  'Sentence': '\\nThe Generator is optimized according to the Discriminator, which is a classification network meant to recognize whether images are “real”'},\n",
              " {'Label': 'Neural network artworks',\n",
              "  'Sentence': '\\nIn other words, GAN generator nets have learned how to plausibly compose objects together in scenes and to texture the object parts, following the instructions encoded in the vector z'},\n",
              " {'Label': 'Neural network artworks',\n",
              "  'Sentence': '\\nThis method was trained on ImageNet, an enormous and diverse collection of real-world images; based on the training details in the paper, it has been estimated that model training used an amount of power consumption equivalent to a typical US household’s usage over 6 months'},\n",
              " {'Label': 'Neural network artworks',\n",
              "  'Sentence': '\\nMuch of the work that artists do with GANs is to explore the latent space and experiment with different ways to generate z vectors'},\n",
              " {'Label': 'Neural network artworks',\n",
              "  'Sentence': '\\nWe now apply the theory to image stylization algorithms'},\n",
              " {'Label': 'Neural network artworks',\n",
              "  'Sentence': '\\nThese algorithms take a natural image as input and output a stylized version, such as a painting'},\n",
              " {'Label': 'Neural network artworks',\n",
              "  'Sentence': '\\nThey often express this task as an optimization that trades-off two goals: producing an image that has the overall appearance and structure of the given photograph, while also constructing the image from style elements, such as paint strokes or tiles'},\n",
              " {'Label': 'Neural network artworks',\n",
              "  'Sentence': '\\nThat is, the image appears to be a real scene but also appears to be composed of unrelated texture'},\n",
              " {'Label': 'Neural network artworks',\n",
              "  'Sentence': '\\nNeural image translation methods, like pix2pix and CycleGAN, learn to transform images, given before-and-after pairs as training'},\n",
              " {'Label': 'Neural network artworks',\n",
              "  'Sentence': '\\nRather than attemping to model natural images, they model image transformations'},\n",
              " {'Label': 'Neural network artworks',\n",
              "  'Sentence': '\\nIn this case, the GAN creates a new visual style for input imagery, rather than creating new imagery from scratch'},\n",
              " {'Label': 'Neural network artworks',\n",
              "  'Sentence': '\\nAnother class of works also arose from attempts to visualize neural network classifiers'},\n",
              " {'Label': 'Neural network artworks',\n",
              "  'Sentence': '\\nTom White’s “Perception Engines” series combines classifier visualization with stroke-based optimization, while producing an intriguing new take on abstract art'},\n",
              " {'Label': 'Neural network artworks',\n",
              "  'Sentence': '\\nThese images are optimized according to natural image classifiers that are trained to distinguish photographs from one another, for example, looking for cues that distinguish photos of, say, violins from any other object class'},\n",
              " {'Label': 'Neural network artworks',\n",
              "  'Sentence': '\\nIn each of these cases, there is a tension between the apparent abstraction of the image strokes and the object class cues specified by the classifier'},\n",
              " {'Label': 'Neural network artworks',\n",
              "  'Sentence': '\\nGiven ongoing battles in our society over which kinds of images are offensive and why, they provide an interesting example of how something can seem somehow “obscene” while being purely abstract'},\n",
              " {'Label': 'Neural network artworks',\n",
              "  'Sentence': '\\nAs described above, realistic drawings get some of their appeal from depicting natural scenes with specific style elements'},\n",
              " {'Label': 'Neural network artworks',\n",
              "  'Sentence': '\\nThis suggests the following interpretation of Pollock’s paintings: they are interesting because they juxtapose some overall cues of natural scenes with fine details that are completely non-naturalistic'},\n",
              " {'Label': 'Neural network artworks',\n",
              "  'Sentence': '\\nHis entirely-abstract Ocean Park series explicitly references landscapes in the title, the colors, and the layout of abstract shapes'},\n",
              " {'Label': 'Neural network artworks',\n",
              "  'Sentence': '\\nIn this way, Tom White’s abstract stroke arrangements can be thought of as an implementation of an explicit model of some abstract expressionism: creating abstract arrangements with some of the statistics of natural images'},\n",
              " {'Label': 'Neural network artworks',\n",
              "  'Sentence': '\\nThis paper presents a sort of recipe for making interesting images: begin with the latest research in natural image modeling, and then modify some elements of the model while preserving others'},\n",
              " {'Label': 'Neural network artworks',\n",
              "  'Sentence': '\\nAs new models are developed, trained, and released in the coming years, we can expect that artists will continue to seize on these models and exploit them to create new and fascinating imagery'},\n",
              " {'Label': 'Neural network artworks',\n",
              "  'Sentence': '\\nEven if new GANs become flawless, artists will still tweak them to produce surprising new imagery'},\n",
              " {'Label': 'Neural network artworks',\n",
              "  'Sentence': '\\nIn fine art, especially painting, humans have mastered the skill to create unique visual experiences through composing a complex interplay between the content and style of an image'},\n",
              " {'Label': 'Neural network artworks',\n",
              "  'Sentence': '\\nThus far the algorithmic basis of this process is unknown and there exists no artificial system with similar capabilities'},\n",
              " {'Label': 'Neural network artworks',\n",
              "  'Sentence': '\\nHere we introduce an artificial system based on a Deep Neural Network that creates artistic images of high perceptual quality'},\n",
              " {'Label': 'Neural network artworks',\n",
              "  'Sentence': '\\nThe system uses neural representations to separate and recombine content and style of arbitrary images, providing a neural algorithm for the creation of artistic images'},\n",
              " {'Label': 'Neural network artworks',\n",
              "  'Sentence': '\\nThe class of Deep Neural Networks that are most powerful in image processing tasks are called Convolutional Neural Networks'},\n",
              " {'Label': 'Neural network artworks',\n",
              "  'Sentence': '\\nEach layer of units can be understood as a collection of image filters, each of which extracts a certain feature from the input image'},\n",
              " {'Label': 'Neural network artworks',\n",
              "  'Sentence': '\\nWhen Convolutional Neural Networks are trained on object recognition, they develop a representation of the image that makes object information increasingly explicit along the processing hierarchy'},\n",
              " {'Label': 'Neural network artworks',\n",
              "  'Sentence': '\\nWe can directly visualise the information each layer contains about the input image by reconstructing the image only from the feature maps in that layer (Fig 1, content reconstructions, see Methods for details on how to reconstruct the image)'},\n",
              " {'Label': 'Neural network artworks',\n",
              "  'Sentence': '\\nTo obtain a representation of the style of an input image, we use a feature space originally designed to capture texture information'},\n",
              " {'Label': 'Neural network artworks',\n",
              "  'Sentence': '\\nWhile the number of different filters increases along the processing hierarchy, the size of the filtered images is reduced by some downsampling mechanism (e'},\n",
              " {'Label': 'Neural network artworks', 'Sentence': 'g'},\n",
              " {'Label': 'Neural network artworks',\n",
              "  'Sentence': ' max-pooling) leading to a decrease in the total number of units per layer of the network'},\n",
              " {'Label': 'Neural network artworks',\n",
              "  'Sentence': '\\nA given input image is represented as a set of filtered images at each processing stage in the CNN'},\n",
              " {'Label': 'Neural network artworks',\n",
              "  'Sentence': '\\nOn top of the original CNN representations we built a new feature space that captures the style of an input image'},\n",
              " {'Label': 'Neural network artworks',\n",
              "  'Sentence': '\\nMoreover, the size and complexity of local image structures from the input image increases along the hierarchy, a result that can be explained by the increasing receptive field sizes and feature complexity'},\n",
              " {'Label': 'Neural network artworks',\n",
              "  'Sentence': '\\nThat is, we can manipulate both representations independently to produce new, perceptually meaningful images'},\n",
              " {'Label': 'Neural network artworks',\n",
              "  'Sentence': '\\nWhen matching the style representations up to higher layers in the network, local images structures are matched on an increasingly large scale, leading to a smoother and more continuous visual experience'},\n",
              " {'Label': 'Neural network artworks',\n",
              "  'Sentence': '\\nThus, the visually most appealing images are usually created by matching the style representation up to the highest layers in the network'},\n",
              " {'Label': 'Neural network artworks',\n",
              "  'Sentence': '\\nWhen synthesising an image that combines the content of one image with the style of another, there usually does not exist an image that perfectly matches both constraints at the same time'},\n",
              " {'Label': 'Neural network artworks',\n",
              "  'Sentence': '\\nA strong emphasis on style will result in images that match the appearance of the artwork, effectively giving a texturised version of it, but hardly show any of the photograph’s content'},\n",
              " {'Label': 'Neural network artworks',\n",
              "  'Sentence': '\\nHere we present an artificial neural system that achieves a separation of image content from style, thus allowing to recast the content of one image in the style of any other image'},\n",
              " {'Label': 'Neural network artworks',\n",
              "  'Sentence': '\\nIn particular, we derive the neural representations for the content and style of an image from the feature responses of highperforming Deep Neural Networks trained on object recognition'},\n",
              " {'Label': 'Neural network artworks',\n",
              "  'Sentence': '\\nConceptually most closely related are methods using texture transfer to achieve artistic style transfer'},\n",
              " {'Label': 'Neural network artworks',\n",
              "  'Sentence': '\\nIn contrast, by using Deep Neural Networks trained on object recognition, we carry out manipulations in feature spaces that explicitly represent the high level content of an image'},\n",
              " {'Label': 'Neural network artworks',\n",
              "  'Sentence': '\\nFeatures from Deep Neural Networks trained on object recognition have been previously used for style recognition in order to classify artworks according to the period in which they were created'},\n",
              " {'Label': 'Neural network artworks',\n",
              "  'Sentence': '\\nWe conjecture that a transformation into a stationary feature space such as our style representation might achieve even better performance in style classification'},\n",
              " {'Label': 'Neural network artworks',\n",
              "  'Sentence': '\\nAll in all it is truly fascinating that a neural system, which is trained to perform one of the core computational tasks of biological vision, automatically learns image representations that allow the separation of image content from style'},\n",
              " {'Label': 'Neural network artworks',\n",
              "  'Sentence': '\\nThus, our ability to abstract content from style and therefore our ability to create and enjoy art might be primarily a preeminent signature of the powerful inference capabilities of our visual system'},\n",
              " {'Label': 'Neural network artworks',\n",
              "  'Sentence': '\\nIn texture transfer the goal is to synthesise a texture from a source image while constraining the texture synthesis in order to preserve the semantic content of a target image'},\n",
              " {'Label': 'Neural network artworks',\n",
              "  'Sentence': '\\nMost previous texture transfer algorithms rely on these nonparametric methods for texture synthesis while using different ways to preserve the structure of the target image'},\n",
              " {'Label': 'Neural network artworks',\n",
              "  'Sentence': '\\nAlthough these algorithms achieve remarkable results, they all suffer from the same fundamental limitation: they use only low-level image features of the target image to inform the texture transfer'},\n",
              " {'Label': 'Neural network artworks',\n",
              "  'Sentence': '\\nHere we demonstrate how to use feature representations from high-performing Convolutional Neural Networks to transfer image style between arbitrary images'},\n",
              " {'Label': 'Neural network artworks',\n",
              "  'Sentence': '\\nWhile this is less of an issue in the artistic style transfer, the problem becomes more apparent when both, content and style images, are photographs and the photorealism of the synthesised image is affected'},\n",
              " {'Label': 'Neural network artworks',\n",
              "  'Sentence': '\\nArtistic stylisation of images is traditionally studied in computer graphics under the label of non-photorealistic rendering'},\n",
              " {'Label': 'Neural network artworks',\n",
              "  'Sentence': '\\nThis paper presents a multi-stage machine learning approach to the problem of semantic categorization of images depicting fine art paintings'},\n",
              " {'Label': 'Neural network artworks',\n",
              "  'Sentence': '\\nThe ability to recognize an artistic style in fine art paintings is an attribute of highly educated and experienced art scholars who spend years analyzing and learning the specifics and nuances of the fine art objects'},\n",
              " {'Label': 'Neural network artworks',\n",
              "  'Sentence': '\\nDue to the rapidly expanding availability of the online galleries, as well as various other sources of fine art pictures, fine art has become accessible to the masses, which in turn created a need to make the art expertise more easily available to the public'},\n",
              " {'Label': 'Neural network artworks',\n",
              "  'Sentence': '\\nMachine-based art expertise can be used in automatic image retrieval, in art classes and in labeling of unsigned paintings at auction houses'},\n",
              " {'Label': 'Neural network artworks',\n",
              "  'Sentence': '\\nIn visual arts, style is defined as a set of distinctive elements that can be associated with a specific artistic movement, school or time period'},\n",
              " {'Label': 'Neural network artworks',\n",
              "  'Sentence': '\\nTransfer learning allows the adaptation or reuse of a network model that has been trained for a specific task using a very large dataset to perform a new, related task for which only a small dataset is available'},\n",
              " {'Label': 'Neural network artworks',\n",
              "  'Sentence': '\\nOne of the possible reasons is that standard CNN architectures, used in most studies, require a fixed input image size that is in most cases, significantly smaller than the high-resolution art images offered by fine art datasets'},\n",
              " {'Label': 'Neural network artworks',\n",
              "  'Sentence': '\\nTo address this problem, a sub-region approach was introduced in which the original image is divided into smaller regions (or image patches), where the size of each patch matches the standard image input size required by the CNN model'},\n",
              " {'Label': 'Neural network artworks',\n",
              "  'Sentence': '\\nFirst, the proposed approach divides the input image into patches and applies a deep neural network to train and classify each patch'},\n",
              " {'Label': 'Neural network artworks',\n",
              "  'Sentence': '\\nThe fine art classification task has been addressed through a wide range of methods'},\n",
              " {'Label': 'Neural network artworks',\n",
              "  'Sentence': '\\nTwenty-five styles represented by a large dataset of digitized paintings were categorized using features generated by a pre-trained CNN model'},\n",
              " {'Label': 'Neural network artworks',\n",
              "  'Sentence': '\\nFurther improvement of style classification was achieved through the application of transfer learning with the CNN model used to do both, feature learning and label inference'},\n",
              " {'Label': 'Neural network artworks',\n",
              "  'Sentence': '\\nThe findings revealed a strong correlation between the CNN features and the chronology of paintings'},\n",
              " {'Label': 'Neural network artworks',\n",
              "  'Sentence': '\\nThe study implemented the SVM model trained on features extracted from the CNN model to perform a binary identification of Vincent van Gogh’s paintings'},\n",
              " {'Label': 'Neural network artworks',\n",
              "  'Sentence': '\\nArtist recognition based images of paper prints of artworks were performed using the average score obtained by independent CNNs trained on different image scales'},\n",
              " {'Label': 'Neural network artworks',\n",
              "  'Sentence': '\\nA complex three-branch CNN structure was trained using a dataset of 2338 images with 13 categories to classify paintings by style'},\n",
              " {'Label': 'Neural network artworks',\n",
              "  'Sentence': '\\nWhile the first stage deep CNN classifier is trained on images, the second stage shallow NN is trained on the class-probability vectors resulting from the first stage classification'},\n",
              " {'Label': 'Neural network artworks',\n",
              "  'Sentence': '\\nThree datasets of digital images of paintings collated from publicly available fine art collections, with the addition of an Australian Aboriginal art dataset created by the authors, were used to empirically validate the efficacy of the proposed method'},\n",
              " {'Label': 'Neural network artworks',\n",
              "  'Sentence': '\\nThe stylistic classes were balanced, and each class was represented by 5145 images (16'},\n",
              " {'Label': 'Neural network artworks',\n",
              "  'Sentence': '66% of the total number of pictures)'},\n",
              " {'Label': 'Neural network artworks',\n",
              "  'Sentence': '\\nIt confirms the benefits of having a second-stage classifier trained not on the images but on the class-probability vectors'},\n",
              " {'Label': 'Neural network artworks',\n",
              "  'Sentence': '\\nIt can be noticed that the higher the CNN complexity, the better the classification outcomes disregarding the method and the database'},\n",
              " {'Label': 'Neural network artworks',\n",
              "  'Sentence': '\\nA new machine learning method for automatic fine art style classification was presented and evaluated'},\n",
              " {'Label': 'Neural network artworks',\n",
              "  'Sentence': '\\nIn this paper we will talk about the development of computer programs capable of creating artworks'},\n",
              " {'Label': 'Neural network artworks',\n",
              "  'Sentence': '\\nThe vast majority of AI applications in the field of the arts falls into two categories: Systems performing some sort of art understanding task, such as musical analysis, and systems that work as “intelligent” tools for human artists (Spector & Alpern 1994); and a new range of applications that is beginning to emerge, the constructed artists which “are supposed to be capable of creating aesthetically meritorious artworks on their own, with minimal human intervention'},\n",
              " {'Label': 'Neural network artworks',\n",
              "  'Sentence': '\\nIn the development of a model for a “constructed artist”, we took into consideration the previously referred characteristics that a constructed artist should have'},\n",
              " {'Label': 'Neural network artworks',\n",
              "  'Sentence': '\\nFor the generation of the images, we rely on a Genetic Algorithm'},\n",
              " {'Label': 'Neural network artworks',\n",
              "  'Sentence': '\\nThis type of approach relies on the assumption that the combination of two highly fit images results, at least generally, in a fit image'},\n",
              " {'Label': 'Neural network artworks',\n",
              "  'Sentence': '\\nIn the proposed system, a convolutional neural network is learned so that images can be classified into a group based on a touch, with saturation and value and the histogram of saturation and value as input data, and the trained network is used to realize the retrieval'},\n",
              " {'Label': 'Neural network artworks',\n",
              "  'Sentence': '\\xa0\\nThen, the image and the normalized feature vector corresponding to the image are associated and stored in the database'},\n",
              " {'Label': 'Neural network artworks',\n",
              "  'Sentence': '\\nIn this paper, we explore the secret nature of human painting and propose an automatic image-to-painting translation method that generates vivid and realistic paintings with controllable styles'},\n",
              " {'Label': 'Neural network artworks',\n",
              "  'Sentence': '\\nOur method can “draw” in a variety of painting styles, e'},\n",
              " {'Label': 'Neural network artworks', 'Sentence': 'g'},\n",
              " {'Label': 'Neural network artworks',\n",
              "  'Sentence': ' oil-painting brush, watercolor ink, marker-pen, and tape art'},\n",
              " {'Label': 'Neural network artworks',\n",
              "  'Sentence': '\\nWe test our method on various real-world images and photos, including human portraits, animals, scenery, daily objects, art photography, and cartoon images'},\n",
              " {'Label': 'Neural network artworks',\n",
              "  'Sentence': '\\nWe propose a new method for stroke based image-topainting translation'},\n",
              " {'Label': 'Neural network artworks',\n",
              "  'Sentence': '\\nTo build a neural renderer, a general practice is to build a deep convolutional network and train it to imitate the behavior of a graphic engine'},\n",
              " {'Label': 'Neural network artworks',\n",
              "  'Sentence': '\\nWe can see that our method successfully learns high-level abstractions of the characters and vividly portrays their shape and color'},\n",
              " {'Label': 'Neural network artworks',\n",
              "  'Sentence': '\\nWe can see our method generates more vivid results with a clear distinction on brush textures, while the method “Learning-to-Paint” tends to produce blurred results'},\n",
              " {'Label': 'Neural network artworks',\n",
              "  'Sentence': '\\nWe consider this artistic creation process under a stroke parameter searching paradigm that maximizes the similarity between the sequentially rendered canvas and the refe'}]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "LrbHarLTh1nu",
        "outputId": "ddca18b7-644b-4bee-ce11-0eaddcfd4e96"
      },
      "source": [
        "#creating two columns with information about sentenses\n",
        "new_df = pd.DataFrame(data=new_df, columns=['Sentence', 'Label'])\n",
        "#save separated sentences to csv\n",
        "new_df.to_csv(\"/content/drive/MyDrive/NLP/datavlad.csv\")\n",
        "new_df"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>In the past few years, many artists have begun...</td>\n",
              "      <td>Neural network artworks</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\\nIn computer vision and perceptual psychology...</td>\n",
              "      <td>Neural network artworks</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\\nIn other words, modern neural models lend th...</td>\n",
              "      <td>Neural network artworks</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\\nThe most prominent tool in neural art at the...</td>\n",
              "      <td>Neural network artworks</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\\nGiven a large collection of images of a spec...</td>\n",
              "      <td>Neural network artworks</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100</th>\n",
              "      <td>\\nWe propose a new method for stroke based ima...</td>\n",
              "      <td>Neural network artworks</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101</th>\n",
              "      <td>\\nTo build a neural renderer, a general practi...</td>\n",
              "      <td>Neural network artworks</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102</th>\n",
              "      <td>\\nWe can see that our method successfully lear...</td>\n",
              "      <td>Neural network artworks</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103</th>\n",
              "      <td>\\nWe can see our method generates more vivid r...</td>\n",
              "      <td>Neural network artworks</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104</th>\n",
              "      <td>\\nWe consider this artistic creation process u...</td>\n",
              "      <td>Neural network artworks</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>105 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              Sentence                    Label\n",
              "0    In the past few years, many artists have begun...  Neural network artworks\n",
              "1    \\nIn computer vision and perceptual psychology...  Neural network artworks\n",
              "2    \\nIn other words, modern neural models lend th...  Neural network artworks\n",
              "3    \\nThe most prominent tool in neural art at the...  Neural network artworks\n",
              "4    \\nGiven a large collection of images of a spec...  Neural network artworks\n",
              "..                                                 ...                      ...\n",
              "100  \\nWe propose a new method for stroke based ima...  Neural network artworks\n",
              "101  \\nTo build a neural renderer, a general practi...  Neural network artworks\n",
              "102  \\nWe can see that our method successfully lear...  Neural network artworks\n",
              "103  \\nWe can see our method generates more vivid r...  Neural network artworks\n",
              "104  \\nWe consider this artistic creation process u...  Neural network artworks\n",
              "\n",
              "[105 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "-CkYsz0rMIsQ",
        "outputId": "a4fcc851-13a7-41ec-f3a4-c4c7c469a413"
      },
      "source": [
        "# import libraries\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_split, test_split = train_test_split(new_df, train_size=0.8, test_size=0.2)\n",
        "train_split"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>\\nIn this paper, we explore the secret nature ...</td>\n",
              "      <td>Neural network artworks</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75</th>\n",
              "      <td>\\nTwenty-five styles represented by a large da...</td>\n",
              "      <td>Neural network artworks</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\\nThe most prominent tool in neural art at the...</td>\n",
              "      <td>Neural network artworks</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>\\nGANs are the latest in a long line of resear...</td>\n",
              "      <td>Neural network artworks</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65</th>\n",
              "      <td>\\nThis paper presents a multi-stage machine le...</td>\n",
              "      <td>Neural network artworks</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>\\nEven if new GANs become flawless, artists wi...</td>\n",
              "      <td>Neural network artworks</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>\\nThus far the algorithmic basis of this proce...</td>\n",
              "      <td>Neural network artworks</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82</th>\n",
              "      <td>\\nThree datasets of digital images of painting...</td>\n",
              "      <td>Neural network artworks</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>\\nArtistic stylisation of images is traditiona...</td>\n",
              "      <td>Neural network artworks</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>\\nThis suggests the following interpretation o...</td>\n",
              "      <td>Neural network artworks</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>84 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             Sentence                    Label\n",
              "95  \\nIn this paper, we explore the secret nature ...  Neural network artworks\n",
              "75  \\nTwenty-five styles represented by a large da...  Neural network artworks\n",
              "3   \\nThe most prominent tool in neural art at the...  Neural network artworks\n",
              "6   \\nGANs are the latest in a long line of resear...  Neural network artworks\n",
              "65  \\nThis paper presents a multi-stage machine le...  Neural network artworks\n",
              "..                                                ...                      ...\n",
              "30  \\nEven if new GANs become flawless, artists wi...  Neural network artworks\n",
              "32  \\nThus far the algorithmic basis of this proce...  Neural network artworks\n",
              "82  \\nThree datasets of digital images of painting...  Neural network artworks\n",
              "64  \\nArtistic stylisation of images is traditiona...  Neural network artworks\n",
              "25  \\nThis suggests the following interpretation o...  Neural network artworks\n",
              "\n",
              "[84 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yH2lL0PIh5ZS",
        "outputId": "d9f751cc-9230-4d05-99bb-36dc6720b8f1"
      },
      "source": [
        "# vectorization of text\n",
        "max_tokens = 10000\n",
        "count = 0\n",
        "\n",
        "for new in sentences:\n",
        "  count+=len(new.split())\n",
        "avg_tokens = round(count/len(sentences))\n",
        "avg_tokens"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QaXJGCCyGz-Q",
        "outputId": "65890a6b-3d18-4e22-bd75-dedb7c6fec3c"
      },
      "source": [
        "text_vectorizer = TextVectorization(max_tokens=max_tokens, # how many words in the vocabulary (all of the different words in your text)\n",
        "                                    standardize=\"lower_and_strip_punctuation\", # how to process text\n",
        "                                    split=\"whitespace\", # how to split tokens\n",
        "                                    ngrams=None, # create groups of n-words?\n",
        "                                    output_mode=\"int\", # how to map tokens to numbers\n",
        "                                    output_sequence_length=avg_tokens, # how long should the output sequence of tokens be?\n",
        "                                    pad_to_max_tokens=True)\n",
        "text_vectorizer.adapt(new_df['Sentence'])\n",
        "\n",
        "text_vectorizer(new_df['Sentence'])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(105, 24), dtype=int64, numpy=\n",
              "array([[  6,   2, 521, ...,   5, 797,   6],\n",
              "       [  6, 157, 123, ...,   0,   0,   0],\n",
              "       [  6,  74, 174, ..., 562, 131, 155],\n",
              "       ...,\n",
              "       [ 16,  26, 137, ...,   0,   0,   0],\n",
              "       [ 16,  26, 137, ...,   5,  99, 767],\n",
              "       [ 16, 734,  24, ...,   7,   2, 471]])>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6LuArsSqKAsp",
        "outputId": "bfea123d-2f1b-40da-84d5-e9a0689cfc17"
      },
      "source": [
        "print(f\"Most Used: {text_vectorizer.get_vocabulary()[:5]}\")\n",
        "print(f\"Most Unused: {text_vectorizer.get_vocabulary()[-5:]}\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most Used: ['', '[UNK]', 'the', 'of', 'a']\n",
            "Most Unused: ['2338', '1994', '16', '13', '1']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iqX5x1xaKj8g",
        "outputId": "6e337549-4d26-465b-9992-55e0be9ee08b"
      },
      "source": [
        "# embedding of data\n",
        "embedding = layers.Embedding(input_dim=max_tokens, # set input shape\n",
        "                             output_dim=128, # set size of embedding vector\n",
        "                             embeddings_initializer=\"uniform\", # default, intialize randomly\n",
        "                             input_length=avg_tokens) # how long is each input\n",
        "\n",
        "embedding(text_vectorizer(new_df['Sentence']))\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(105, 24, 128), dtype=float32, numpy=\n",
              "array([[[ 1.16179697e-02, -6.89704344e-03, -4.85221259e-02, ...,\n",
              "         -4.04276848e-02,  3.04611661e-02, -4.30170186e-02],\n",
              "        [ 3.91794704e-02,  8.12895223e-03,  4.17335294e-02, ...,\n",
              "         -4.91617918e-02, -8.18390772e-03, -4.14472930e-02],\n",
              "        [-2.54979264e-02, -8.25766474e-03, -1.68346539e-02, ...,\n",
              "         -1.45431869e-02,  2.33328827e-02, -1.59457326e-02],\n",
              "        ...,\n",
              "        [ 1.08373985e-02, -1.49660595e-02,  4.01986949e-02, ...,\n",
              "         -2.36765631e-02, -7.72241503e-03, -2.43506581e-03],\n",
              "        [-3.12988311e-02, -4.88207228e-02, -2.27710009e-02, ...,\n",
              "          2.13618390e-02,  4.37307470e-02, -1.55324340e-02],\n",
              "        [ 1.16179697e-02, -6.89704344e-03, -4.85221259e-02, ...,\n",
              "         -4.04276848e-02,  3.04611661e-02, -4.30170186e-02]],\n",
              "\n",
              "       [[ 1.16179697e-02, -6.89704344e-03, -4.85221259e-02, ...,\n",
              "         -4.04276848e-02,  3.04611661e-02, -4.30170186e-02],\n",
              "        [ 2.47412436e-02,  2.25798823e-02,  2.91186683e-02, ...,\n",
              "         -1.91399809e-02,  3.53858806e-02,  4.87241186e-02],\n",
              "        [-3.01707909e-03,  4.87827547e-02,  3.70943211e-02, ...,\n",
              "          3.09236348e-05, -4.93556038e-02, -8.47931951e-03],\n",
              "        ...,\n",
              "        [ 8.02897289e-03,  1.20510235e-02, -2.54936460e-02, ...,\n",
              "         -1.45511702e-03, -3.48690525e-02, -1.56093724e-02],\n",
              "        [ 8.02897289e-03,  1.20510235e-02, -2.54936460e-02, ...,\n",
              "         -1.45511702e-03, -3.48690525e-02, -1.56093724e-02],\n",
              "        [ 8.02897289e-03,  1.20510235e-02, -2.54936460e-02, ...,\n",
              "         -1.45511702e-03, -3.48690525e-02, -1.56093724e-02]],\n",
              "\n",
              "       [[ 1.16179697e-02, -6.89704344e-03, -4.85221259e-02, ...,\n",
              "         -4.04276848e-02,  3.04611661e-02, -4.30170186e-02],\n",
              "        [ 2.36339904e-02, -8.47028568e-03,  4.07245494e-02, ...,\n",
              "         -1.47424564e-02,  4.47134711e-02,  3.89938019e-02],\n",
              "        [ 4.55386378e-02,  1.29003450e-03, -4.03087214e-03, ...,\n",
              "          1.75689533e-03, -4.97922078e-02,  2.72443146e-03],\n",
              "        ...,\n",
              "        [-1.21971481e-02, -3.33433300e-02, -3.52793932e-02, ...,\n",
              "          3.61116268e-02,  2.11876370e-02, -9.37491655e-03],\n",
              "        [-9.86287743e-03, -4.99914661e-02,  1.25109814e-02, ...,\n",
              "          4.68434952e-02,  4.35216539e-02,  7.58509710e-03],\n",
              "        [-2.47003883e-03,  4.03279103e-02,  2.91418321e-02, ...,\n",
              "          1.99783593e-04,  3.73395719e-02, -1.15273818e-02]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[-2.82436498e-02,  6.56386465e-03,  4.58055846e-02, ...,\n",
              "         -1.34756081e-02,  3.61687802e-02, -5.15536219e-03],\n",
              "        [-4.96002287e-03,  3.61528881e-02, -9.89387184e-03, ...,\n",
              "          4.42372002e-02,  2.71092393e-02,  4.97951396e-02],\n",
              "        [ 3.12992819e-02, -1.71301477e-02,  1.26790255e-04, ...,\n",
              "          3.25750448e-02, -4.44064252e-02, -4.86534610e-02],\n",
              "        ...,\n",
              "        [ 8.02897289e-03,  1.20510235e-02, -2.54936460e-02, ...,\n",
              "         -1.45511702e-03, -3.48690525e-02, -1.56093724e-02],\n",
              "        [ 8.02897289e-03,  1.20510235e-02, -2.54936460e-02, ...,\n",
              "         -1.45511702e-03, -3.48690525e-02, -1.56093724e-02],\n",
              "        [ 8.02897289e-03,  1.20510235e-02, -2.54936460e-02, ...,\n",
              "         -1.45511702e-03, -3.48690525e-02, -1.56093724e-02]],\n",
              "\n",
              "       [[-2.82436498e-02,  6.56386465e-03,  4.58055846e-02, ...,\n",
              "         -1.34756081e-02,  3.61687802e-02, -5.15536219e-03],\n",
              "        [-4.96002287e-03,  3.61528881e-02, -9.89387184e-03, ...,\n",
              "          4.42372002e-02,  2.71092393e-02,  4.97951396e-02],\n",
              "        [ 3.12992819e-02, -1.71301477e-02,  1.26790255e-04, ...,\n",
              "          3.25750448e-02, -4.44064252e-02, -4.86534610e-02],\n",
              "        ...,\n",
              "        [ 1.08373985e-02, -1.49660595e-02,  4.01986949e-02, ...,\n",
              "         -2.36765631e-02, -7.72241503e-03, -2.43506581e-03],\n",
              "        [ 1.89343579e-02,  1.16672292e-02, -3.79985087e-02, ...,\n",
              "         -2.85347458e-02,  3.80220264e-03, -3.92710455e-02],\n",
              "        [ 4.13341187e-02,  6.93701580e-03,  4.91001643e-02, ...,\n",
              "         -1.04004256e-02,  2.11277939e-02, -3.98293249e-02]],\n",
              "\n",
              "       [[-2.82436498e-02,  6.56386465e-03,  4.58055846e-02, ...,\n",
              "         -1.34756081e-02,  3.61687802e-02, -5.15536219e-03],\n",
              "        [-3.39087248e-02, -3.06015611e-02,  1.41814239e-02, ...,\n",
              "          1.77953281e-02, -4.98263910e-03, -2.15918422e-02],\n",
              "        [ 2.30475105e-02, -2.61119362e-02,  8.56680796e-03, ...,\n",
              "         -4.96431254e-02,  2.30624340e-02, -1.11705177e-02],\n",
              "        ...,\n",
              "        [-1.69647224e-02,  1.68019570e-02,  4.46579717e-02, ...,\n",
              "         -1.83918104e-02,  4.92886566e-02,  9.24336910e-03],\n",
              "        [ 3.91794704e-02,  8.12895223e-03,  4.17335294e-02, ...,\n",
              "         -4.91617918e-02, -8.18390772e-03, -4.14472930e-02],\n",
              "        [ 4.57228348e-03, -4.28103283e-03,  1.99793018e-02, ...,\n",
              "          2.97105312e-03, -9.61910561e-03, -2.60234959e-02]]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    }
  ]
}